{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "48683a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "c6ca271b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"breast cancer diagnosis .csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "c627c893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Start Age  End Age menopause  Start tumor size  End tumor size  \\\n",
      "0         40       49   premeno                15              19   \n",
      "1         50       59      ge40                15              19   \n",
      "2         50       59      ge40                35              39   \n",
      "\n",
      "   Start_env_nodes  end_env_nodes node-caps  deg-malig breast breast-quad  \\\n",
      "0                0              2       yes          3  right     left_up   \n",
      "1                0              2        no          1  right     central   \n",
      "2                0              2        no          2   left    left_low   \n",
      "\n",
      "  irradiat                 Class  \n",
      "0       no     recurrence-events  \n",
      "1       no  no-recurrence-events  \n",
      "2       no     recurrence-events  \n"
     ]
    }
   ],
   "source": [
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "49fa84d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Age           0\n",
      "End Age             0\n",
      "menopause           0\n",
      "Start tumor size    0\n",
      "End tumor size      0\n",
      "Start_env_nodes     0\n",
      "end_env_nodes       0\n",
      "node-caps           8\n",
      "deg-malig           0\n",
      "breast              0\n",
      "breast-quad         1\n",
      "irradiat            0\n",
      "Class               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df.replace(\"?\", float(\"nan\"), inplace=True)\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "d6f5cf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 286 entries, 0 to 285\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Start Age         286 non-null    int64 \n",
      " 1   End Age           286 non-null    int64 \n",
      " 2   menopause         286 non-null    object\n",
      " 3   Start tumor size  286 non-null    int64 \n",
      " 4   End tumor size    286 non-null    int64 \n",
      " 5   Start_env_nodes   286 non-null    int64 \n",
      " 6   end_env_nodes     286 non-null    int64 \n",
      " 7   node-caps         278 non-null    object\n",
      " 8   deg-malig         286 non-null    int64 \n",
      " 9   breast            286 non-null    object\n",
      " 10  breast-quad       285 non-null    object\n",
      " 11  irradiat          286 non-null    object\n",
      " 12  Class             286 non-null    object\n",
      "dtypes: int64(7), object(6)\n",
      "memory usage: 29.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "e10189ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Start Age  End Age  menopause  Start tumor size  End tumor size  \\\n",
      "0         40       49          2                15              19   \n",
      "1         50       59          0                15              19   \n",
      "2         50       59          0                35              39   \n",
      "3         40       49          2                35              39   \n",
      "4         40       49          2                30              34   \n",
      "\n",
      "   Start_env_nodes  end_env_nodes  node-caps  deg-malig  breast  breast-quad  \\\n",
      "0                0              2          2          3       1            2   \n",
      "1                0              2          1          1       1            0   \n",
      "2                0              2          1          2       0            1   \n",
      "3                0              2          2          3       1            1   \n",
      "4                3              5          2          2       0            5   \n",
      "\n",
      "   irradiat  Class  \n",
      "0         0      1  \n",
      "1         0      0  \n",
      "2         0      1  \n",
      "3         1      0  \n",
      "4         0      1  \n"
     ]
    }
   ],
   "source": [
    "# Select the categorical attributes to encode\n",
    "categorical_attributes = [ \"menopause\",  \"node-caps\",\"breast\",\"breast-quad\",\"irradiat\",\"Class\"]\n",
    "encoded_values = {}\n",
    "# Perform label encoding for each categorical attribute\n",
    "label_encoder = LabelEncoder()\n",
    "for attribute in categorical_attributes:\n",
    "    df[attribute] = label_encoder.fit_transform(df[attribute].astype(str))\n",
    "    encoded_values[attribute] = dict(zip(range(len(label_encoder.classes_)), label_encoder.classes_))\n",
    "\n",
    "# Check the updated dataframe\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "7101b48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded values for attribute 'menopause':\n",
      "ge40: 0\n",
      "lt40: 1\n",
      "premeno: 2\n",
      "\n",
      "Encoded values for attribute 'node-caps':\n",
      "nan: 0\n",
      "no: 1\n",
      "yes: 2\n",
      "\n",
      "Encoded values for attribute 'breast':\n",
      "left: 0\n",
      "right: 1\n",
      "\n",
      "Encoded values for attribute 'breast-quad':\n",
      "central: 0\n",
      "left_low: 1\n",
      "left_up: 2\n",
      "nan: 3\n",
      "right_low: 4\n",
      "right_up: 5\n",
      "\n",
      "Encoded values for attribute 'irradiat':\n",
      "no: 0\n",
      "yes: 1\n",
      "\n",
      "Encoded values for attribute 'Class':\n",
      "no-recurrence-events: 0\n",
      "recurrence-events: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for attribute, values in encoded_values.items():\n",
    "    print(f\"Encoded values for attribute '{attribute}':\")\n",
    "    for encoded_value, original_value in values.items():\n",
    "        print(f\"{original_value}: {encoded_value}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "778f8908",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"Class\", axis=1).values\n",
    "y = df[\"Class\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "bb862cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (228, 12)\n",
      "y_train shape: (228,)\n",
      "X_test shape: (58, 12)\n",
      "y_test shape: (58,)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the shapes of the resulting datasets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "8023bbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(y_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "05747226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([40, 49,  2, 35, 39,  0,  2,  2,  3,  1,  1,  1], dtype=int64)"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "fc712ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc4274d",
   "metadata": {},
   "source": [
    "# logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "92efc3d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.03448275862068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Megha\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create the logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b51cbf",
   "metadata": {},
   "source": [
    "# logistic regession with KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "29e5d22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 70.66545674531154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Megha\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Megha\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Megha\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Megha\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Megha\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "k = 5\n",
    "\n",
    "# Create a KFold object\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "\n",
    "# Initialize a list to store the evaluation scores\n",
    "scores = []\n",
    "\n",
    "# Perform K-fold cross-validation\n",
    "for train_index, val_index in kf.split(X):\n",
    "    # Split the data into training and validation sets\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "    # Initialize the model\n",
    "    model = LogisticRegression()\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the validation data\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    # Calculate the accuracy score\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "    # Store the accuracy score\n",
    "    scores.append(accuracy)\n",
    "\n",
    "# Calculate the average score\n",
    "average_score = sum(scores) / len(scores)\n",
    "print(\"Average Accuracy:\", average_score*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc14f8c3",
   "metadata": {},
   "source": [
    "# Random forest with Logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "80af02eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.27586206896551\n",
      "[0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Megha\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions from both models\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "\n",
    "# Combine predictions as input to the meta-model\n",
    "stacked_X = np.column_stack((rf_predictions, lr_predictions))\n",
    "\n",
    "# Train the meta-model (Logistic Regression)\n",
    "meta_model = LogisticRegression()\n",
    "meta_model.fit(stacked_X, y_test)\n",
    "\n",
    "# Generate final predictions using the meta-model\n",
    "meta_predictions = meta_model.predict(stacked_X)\n",
    "\n",
    "# Calculate accuracy of the final predictions\n",
    "accuracy = accuracy_score(y_test, meta_predictions)\n",
    "print(\"Accuracy:\", accuracy*100)\n",
    "# Save the model\n",
    "joblib.dump(model, 'RandomForest_Logisticregression.pkl')\n",
    "# Load the model\n",
    "loaded_model = joblib.load('RandomForest_Logisticregression.pkl')\n",
    "\n",
    "# Make predictions\n",
    "predictions = loaded_model.predict(X_train[1].reshape(1,-1))\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607cbc08",
   "metadata": {},
   "source": [
    "# LogisticRegression with AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "401982b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.82\n",
      "AdaBoost Accuracy: 0.88\n",
      "SVM Accuracy: 84.5\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "print(\"Logistic Regression Accuracy:\", lr_accuracy)\n",
    "\n",
    "# AdaBoost\n",
    "adaboost_model = AdaBoostClassifier()\n",
    "adaboost_model.fit(X_train, y_train)\n",
    "adaboost_predictions = adaboost_model.predict(X_test)\n",
    "adaboost_accuracy = accuracy_score(y_test, adaboost_predictions)\n",
    "print(\"AdaBoost Accuracy:\", adaboost_accuracy)\n",
    "\n",
    "# SVM\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "print(\"SVM Accuracy:\", svm_accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "0425827e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "model = AdaBoostClassifier(n_estimators=6, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "30ea82a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Megha\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create the Logistic Regression model\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "# Create the AdaBoost classifier with Logistic Regression as the base estimator\n",
    "adaboost_model = AdaBoostClassifier(base_estimator=lr_model)\n",
    "\n",
    "# Fit the AdaBoost classifier on the training data\n",
    "adaboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the combined model\n",
    "predictions = adaboost_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "b8410769",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad58f95",
   "metadata": {},
   "source": [
    "# LogisticRegression with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "c33887b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.0\n"
     ]
    }
   ],
   "source": [
    "# Create the base models\n",
    "logistic_model = LogisticRegression()\n",
    "svm_model = SVC()\n",
    "\n",
    "# Create the Stacking classifier\n",
    "estimators = [('logistic', logistic_model), ('svm', svm_model)]\n",
    "stacking_model = StackingClassifier(estimators=estimators)\n",
    "\n",
    "# Fit the Stacking classifier on the training data\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the combined model\n",
    "predictions = stacking_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c07cba6",
   "metadata": {},
   "source": [
    "# LogisticRegression ,RandomForestClassifier with GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "73151902",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.0\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Split the dataset into training and test sets\n",
    "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Fit individual models\n",
    "logistic_model = LogisticRegression()\n",
    "rf_model = RandomForestClassifier()\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "logistic_model.fit(X_train, y_train)\n",
    "rf_model.fit(X_train, y_train)\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Obtain predictions from each model\n",
    "logistic_predictions = logistic_model.predict(X_test)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "nb_predictions = nb_model.predict(X_test)\n",
    "\n",
    "# Step 4: Combine predictions using VotingClassifier\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[('logistic', logistic_model), ('random_forest', rf_model), ('naive_bayes', nb_model)],\n",
    "    voting='hard'\n",
    ")\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "ensemble_predictions = voting_classifier.predict(X_test)\n",
    "\n",
    "# Step 5: Evaluate the performance of the combined model\n",
    "logistic_accuracy = accuracy_score(y_test, logistic_predictions)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
    "ensemble_accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "print(ensemble_accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77190ca",
   "metadata": {},
   "source": [
    "# RandomForestClassifier with GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "b5296093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.0\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Fit random forest and naive Bayes classifiers\n",
    "rf_model = RandomForestClassifier()\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Obtain predictions from each classifier\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "nb_predictions = nb_model.predict(X_test)\n",
    "\n",
    "# Step 4: Combine predictions using VotingClassifier\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[('random_forest', rf_model), ('naive_bayes', nb_model)],\n",
    "    voting='hard'\n",
    ")\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "ensemble_predictions = voting_classifier.predict(X_test)\n",
    "\n",
    "# Step 5: Evaluate the performance of the combined model\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
    "ensemble_accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "print(ensemble_accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "6907c9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.83\n"
     ]
    }
   ],
   "source": [
    "# Create the base models\n",
    "logistic_model = LogisticRegression()\n",
    "naive_bayes_model = GaussianNB()\n",
    "\n",
    "# Create the Voting classifier\n",
    "estimators = [('logistic', logistic_model), ('naive_bayes', naive_bayes_model)]\n",
    "voting_model = VotingClassifier(estimators=estimators)\n",
    "\n",
    "# Fit the Voting classifier on the training data\n",
    "voting_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the combined model\n",
    "predictions = voting_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35275ec9",
   "metadata": {},
   "source": [
    "# LogisticRegression, RandomForestClassifier with DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "401709c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.5\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Fit logistic regression, random forest, and decision tree classifiers\n",
    "logistic_model = LogisticRegression()\n",
    "rf_model = RandomForestClassifier()\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "logistic_model.fit(X_train, y_train)\n",
    "rf_model.fit(X_train, y_train)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Obtain predictions from each classifier\n",
    "logistic_predictions = logistic_model.predict(X_test)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "\n",
    "# Step 4: Combine predictions using VotingClassifier\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[('logistic', logistic_model), ('random_forest', rf_model), ('decision_tree', dt_model)],\n",
    "    voting='hard'\n",
    ")\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "ensemble_predictions = voting_classifier.predict(X_test)\n",
    "\n",
    "# Step 5: Evaluate the performance of each model and the combined model\n",
    "logistic_accuracy = accuracy_score(y_test, logistic_predictions)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "ensemble_accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "print(ensemble_accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea4008f",
   "metadata": {},
   "source": [
    "# LogisticRegression, RandomForestClassifier, DecisionTreeClassifier with svm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "2f15ea0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.0\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Split the dataset into training and test sets\n",
    "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Fit logistic regression, random forest, decision tree, and SVM classifiers\n",
    "logistic_model = LogisticRegression()\n",
    "rf_model = RandomForestClassifier()\n",
    "dt_model = DecisionTreeClassifier()\n",
    "svm_model = SVC()\n",
    "\n",
    "logistic_model.fit(X_train, y_train)\n",
    "rf_model.fit(X_train, y_train)\n",
    "dt_model.fit(X_train, y_train)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Obtain predictions from each classifier\n",
    "logistic_predictions = logistic_model.predict(X_test)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "\n",
    "# Step 4: Combine predictions using VotingClassifier\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[('logistic', logistic_model), ('random_forest', rf_model), ('decision_tree', dt_model), ('svm', svm_model)],\n",
    "    voting='hard'\n",
    ")\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "ensemble_predictions = voting_classifier.predict(X_test)\n",
    "\n",
    "# Step 5: Evaluate the performance of each model and the combined model\n",
    "logistic_accuracy = accuracy_score(y_test, logistic_predictions)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "ensemble_accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "print(ensemble_accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "4926719f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.855\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Step 1: Split the dataset into training and test sets\n",
    "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Initialize the individual classifiers\n",
    "logistic_model = LogisticRegression()\n",
    "rf_model = RandomForestClassifier()\n",
    "dt_model = DecisionTreeClassifier()\n",
    "nb_model = GaussianNB()\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "# Step 3: Fit the classifiers on the training data\n",
    "logistic_model.fit(X_train, y_train)\n",
    "rf_model.fit(X_train, y_train)\n",
    "dt_model.fit(X_train, y_train)\n",
    "nb_model.fit(X_train, y_train)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Obtain predictions from each classifier\n",
    "logistic_predictions = logistic_model.predict(X_test)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "nb_predictions = nb_model.predict(X_test)\n",
    "knn_predictions = knn_model.predict(X_test)\n",
    "\n",
    "# Step 5: Combine predictions using VotingClassifier\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[('logistic', logistic_model), ('random_forest', rf_model),\n",
    "                ('decision_tree', dt_model), ('naive_bayes', nb_model),\n",
    "                ('knn', knn_model)],\n",
    "    voting='hard'\n",
    ")\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "ensemble_predictions = voting_classifier.predict(X_test)\n",
    "\n",
    "# Step 6: Evaluate the performance of each model and the combined model\n",
    "logistic_accuracy = accuracy_score(y_test, logistic_predictions)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
    "knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
    "ensemble_accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "print(ensemble_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "ca1c1ee9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Megha\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\Megha\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# Apply K-Means clustering on the training data\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(X_train)\n",
    "\n",
    "# Get the cluster assignments for the training and testing data\n",
    "train_clusters = kmeans.predict(X_train)\n",
    "test_clusters = kmeans.predict(X_test)\n",
    "\n",
    "# Create new feature matrices with the original features and cluster assignments\n",
    "X_train_new = np.column_stack((X_train, train_clusters))\n",
    "X_test_new = np.column_stack((X_test, test_clusters))\n",
    "\n",
    "# Create and train the Logistic Regression model with the new feature matrices\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train_new, y_train)\n",
    "\n",
    "# Make predictions using the combined model\n",
    "predictions = logistic_model.predict(X_test_new)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "8a11054d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.845\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Split the dataset into training and test sets\n",
    "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Fit logistic regression, random forest, decision tree, Naive Bayes, k-NN, and SVM models\n",
    "logistic_model = LogisticRegression()\n",
    "rf_model = RandomForestClassifier()\n",
    "dt_model = DecisionTreeClassifier()\n",
    "nb_model = GaussianNB()\n",
    "knn_model = KNeighborsClassifier()\n",
    "svm_model = SVC()\n",
    "\n",
    "logistic_model.fit(X_train, y_train)\n",
    "rf_model.fit(X_train, y_train)\n",
    "dt_model.fit(X_train, y_train)\n",
    "nb_model.fit(X_train, y_train)\n",
    "knn_model.fit(X_train, y_train)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Obtain predictions from each classifier\n",
    "logistic_predictions = logistic_model.predict(X_test)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "nb_predictions = nb_model.predict(X_test)\n",
    "knn_predictions = knn_model.predict(X_test)\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "\n",
    "# Step 4: Combine predictions using VotingClassifier\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[('logistic', logistic_model), ('random_forest', rf_model), ('decision_tree', dt_model),\n",
    "                ('naive_bayes', nb_model), ('knn', knn_model), ('svm', svm_model)],\n",
    "    voting='hard'\n",
    ")\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "ensemble_predictions = voting_classifier.predict(X_test)\n",
    "\n",
    "# Step 5: Evaluate the performance of each model and the combined model\n",
    "logistic_accuracy = accuracy_score(y_test, logistic_predictions)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
    "knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "ensemble_accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "print(ensemble_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "6678ede7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Split the dataset into training and test sets\n",
    "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Fit logistic regression, random forest, Naive Bayes, k-NN, and SVM models\n",
    "logistic_model = LogisticRegression()\n",
    "rf_model = RandomForestClassifier()\n",
    "nb_model = GaussianNB()\n",
    "knn_model = KNeighborsClassifier()\n",
    "svm_model = SVC()\n",
    "\n",
    "logistic_model.fit(X_train, y_train)\n",
    "rf_model.fit(X_train, y_train)\n",
    "nb_model.fit(X_train, y_train)\n",
    "knn_model.fit(X_train, y_train)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Obtain predictions from each classifier\n",
    "logistic_predictions = logistic_model.predict(X_test)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "nb_predictions = nb_model.predict(X_test)\n",
    "knn_predictions = knn_model.predict(X_test)\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "\n",
    "# Step 4: Combine predictions using VotingClassifier\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[('logistic', logistic_model), ('random_forest', rf_model),\n",
    "                ('naive_bayes', nb_model), ('knn', knn_model), ('svm', svm_model)],\n",
    "    voting='hard'\n",
    ")\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "ensemble_predictions = voting_classifier.predict(X_test)\n",
    "\n",
    "# Step 5: Evaluate the performance of each model and the combined model\n",
    "logistic_accuracy = accuracy_score(y_test, logistic_predictions)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
    "knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "ensemble_accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "print(ensemble_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "e4ede454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.855\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Split the dataset into training and test sets\n",
    "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Fit random forest, decision tree, Naive Bayes, k-NN, and SVM models\n",
    "rf_model = RandomForestClassifier()\n",
    "dt_model = DecisionTreeClassifier()\n",
    "nb_model = GaussianNB()\n",
    "knn_model = KNeighborsClassifier()\n",
    "svm_model = SVC()\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "dt_model.fit(X_train, y_train)\n",
    "nb_model.fit(X_train, y_train)\n",
    "knn_model.fit(X_train, y_train)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Obtain predictions from each classifier\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "nb_predictions = nb_model.predict(X_test)\n",
    "knn_predictions = knn_model.predict(X_test)\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "\n",
    "# Step 4: Combine predictions using VotingClassifier\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[('random_forest', rf_model),\n",
    "                ('decision_tree', dt_model), ('naive_bayes', nb_model),\n",
    "                ('knn', knn_model), ('svm', svm_model)],\n",
    "    voting='hard'\n",
    ")\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "ensemble_predictions = voting_classifier.predict(X_test)\n",
    "\n",
    "# Step 5: Evaluate the performance of each model and the combined model\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
    "knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "ensemble_accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "print(ensemble_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "f0dadf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Megha\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\Megha\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Apply K-Means clustering on the training data\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(X_train)\n",
    "\n",
    "# Get the cluster assignments for the training and testing data\n",
    "train_clusters = kmeans.predict(X_train)\n",
    "test_clusters = kmeans.predict(X_test)\n",
    "\n",
    "# Create new feature matrices with the original features and cluster assignments\n",
    "X_train_new = np.column_stack((X_train, train_clusters))\n",
    "X_test_new = np.column_stack((X_test, test_clusters))\n",
    "\n",
    "# Create and train the Naive Bayes model with the new feature matrices\n",
    "naive_bayes_model = GaussianNB()\n",
    "naive_bayes_model.fit(X_train_new, y_train)\n",
    "\n",
    "# Make predictions using the combined model\n",
    "predictions = naive_bayes_model.predict(X_test_new)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "f1e23060",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Megha\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\Megha\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Megha\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Apply K-Means clustering on the training data\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(X_train)\n",
    "\n",
    "# Get the cluster assignments for the training and testing data\n",
    "train_clusters = kmeans.predict(X_train)\n",
    "test_clusters = kmeans.predict(X_test)\n",
    "\n",
    "# Create new feature matrices with the original features and cluster assignments\n",
    "X_train_new = np.column_stack((X_train, train_clusters))\n",
    "X_test_new = np.column_stack((X_test, test_clusters))\n",
    "\n",
    "# Create a Naive Bayes model as the weak classifier\n",
    "naive_bayes = GaussianNB()\n",
    "\n",
    "# Create an AdaBoost model with Naive Bayes as the base estimator\n",
    "adaboost = AdaBoostClassifier(base_estimator=naive_bayes, n_estimators=50)\n",
    "\n",
    "# Train the AdaBoost model on the new feature matrices\n",
    "adaboost.fit(X_train_new, y_train)\n",
    "\n",
    "# Make predictions using the combined model\n",
    "predictions = adaboost.predict(X_test_new)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "4f45d199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.83\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel='rbf', random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "ab807d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c94667",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "40583dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy *100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "38c3b229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Create the Naive Bayes classifier\n",
    "model = GaussianNB()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "1aa7af6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Fit logistic regression, random forest, decision tree, and Naive Bayes classifiers\n",
    "logistic_model = LogisticRegression()\n",
    "rf_model = RandomForestClassifier()\n",
    "dt_model = DecisionTreeClassifier()\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "logistic_model.fit(X_train, y_train)\n",
    "rf_model.fit(X_train, y_train)\n",
    "dt_model.fit(X_train, y_train)\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Obtain predictions from each classifier\n",
    "logistic_predictions = logistic_model.predict(X_test)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "nb_predictions = nb_model.predict(X_test)\n",
    "\n",
    "# Step 4: Combine predictions using VotingClassifier\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[('logistic', logistic_model), ('random_forest', rf_model), ('decision_tree', dt_model), ('naive_bayes', nb_model)],\n",
    "    voting='hard'\n",
    ")\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "ensemble_predictions = voting_classifier.predict(X_test)\n",
    "\n",
    "# Step 5: Evaluate the performance of each model and the combined model\n",
    "logistic_accuracy = accuracy_score(y_test, logistic_predictions)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
    "ensemble_accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "print(ensemble_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "af95853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Flatten,concatenate,Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Reshape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b400ae8",
   "metadata": {},
   "source": [
    "# CNN-RNN hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "9efe4887",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Convert y_train to categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "e81c4156",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "31/31 [==============================] - 7s 132ms/step - loss: 0.6066 - accuracy: 0.6175\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 4s 130ms/step - loss: 0.4583 - accuracy: 0.8213\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 4s 129ms/step - loss: 0.3837 - accuracy: 0.8400\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 4s 130ms/step - loss: 0.3518 - accuracy: 0.8537\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 4s 131ms/step - loss: 0.4011 - accuracy: 0.8438\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 4s 128ms/step - loss: 0.3415 - accuracy: 0.8600\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 4s 131ms/step - loss: 0.3186 - accuracy: 0.8750\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 4s 130ms/step - loss: 0.3111 - accuracy: 0.8725\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 4s 132ms/step - loss: 0.2994 - accuracy: 0.8788\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 4s 132ms/step - loss: 0.3139 - accuracy: 0.8625\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 4s 130ms/step - loss: 0.2780 - accuracy: 0.8825\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 4s 129ms/step - loss: 0.3018 - accuracy: 0.8788\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 4s 128ms/step - loss: 0.2893 - accuracy: 0.8737\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 4s 127ms/step - loss: 0.2725 - accuracy: 0.8825\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 4s 129ms/step - loss: 0.2760 - accuracy: 0.8850\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 3s 107ms/step - loss: 0.2878 - accuracy: 0.8813\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 0.2790 - accuracy: 0.8838\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 4s 127ms/step - loss: 0.2713 - accuracy: 0.8875\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 4s 129ms/step - loss: 0.2651 - accuracy: 0.8900\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 4s 119ms/step - loss: 0.2828 - accuracy: 0.8788\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 4s 120ms/step - loss: 0.2665 - accuracy: 0.8888\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 4s 120ms/step - loss: 0.2583 - accuracy: 0.8988\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 4s 120ms/step - loss: 0.2439 - accuracy: 0.9013\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 4s 117ms/step - loss: 0.2326 - accuracy: 0.9025\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 4s 118ms/step - loss: 0.2443 - accuracy: 0.9025\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 4s 118ms/step - loss: 0.2357 - accuracy: 0.9038\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 4s 117ms/step - loss: 0.2206 - accuracy: 0.9075\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 4s 119ms/step - loss: 0.2253 - accuracy: 0.9062\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 4s 120ms/step - loss: 0.2034 - accuracy: 0.9162\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 4s 119ms/step - loss: 0.2672 - accuracy: 0.9000\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 4s 120ms/step - loss: 0.2324 - accuracy: 0.9038\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 4s 119ms/step - loss: 0.2446 - accuracy: 0.9000\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 4s 120ms/step - loss: 0.2415 - accuracy: 0.9050\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 4s 120ms/step - loss: 0.2129 - accuracy: 0.9212\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 4s 119ms/step - loss: 0.1918 - accuracy: 0.9212\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 4s 120ms/step - loss: 0.2157 - accuracy: 0.9075\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 4s 120ms/step - loss: 0.2120 - accuracy: 0.9125\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 4s 121ms/step - loss: 0.2156 - accuracy: 0.9200\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 4s 121ms/step - loss: 0.1860 - accuracy: 0.9275\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 4s 118ms/step - loss: 0.2160 - accuracy: 0.9150\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 4s 121ms/step - loss: 0.1701 - accuracy: 0.9312\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 4s 121ms/step - loss: 0.1672 - accuracy: 0.9287\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 4s 123ms/step - loss: 0.1902 - accuracy: 0.9275\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 4s 123ms/step - loss: 0.1905 - accuracy: 0.9250\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 4s 125ms/step - loss: 0.2042 - accuracy: 0.9250\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 4s 123ms/step - loss: 0.1587 - accuracy: 0.9350\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 4s 124ms/step - loss: 0.1451 - accuracy: 0.9463\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 4s 122ms/step - loss: 0.1730 - accuracy: 0.9325\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 4s 121ms/step - loss: 0.1815 - accuracy: 0.9300\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 4s 123ms/step - loss: 0.1596 - accuracy: 0.9362\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 4s 122ms/step - loss: 0.1959 - accuracy: 0.9275\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 4s 120ms/step - loss: 0.1446 - accuracy: 0.9463\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 4s 123ms/step - loss: 0.1446 - accuracy: 0.9362\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 4s 122ms/step - loss: 0.1439 - accuracy: 0.9375\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 4s 123ms/step - loss: 0.1854 - accuracy: 0.9287\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 4s 124ms/step - loss: 0.1726 - accuracy: 0.9350\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 4s 124ms/step - loss: 0.1898 - accuracy: 0.9275\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 4s 124ms/step - loss: 0.2095 - accuracy: 0.9137\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 4s 121ms/step - loss: 0.1676 - accuracy: 0.9388\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 4s 123ms/step - loss: 0.1451 - accuracy: 0.9450\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 4s 126ms/step - loss: 0.1387 - accuracy: 0.9488\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 4s 122ms/step - loss: 0.2084 - accuracy: 0.9250\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 4s 123ms/step - loss: 0.1503 - accuracy: 0.9525\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 4s 123ms/step - loss: 0.1403 - accuracy: 0.9400\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 4s 121ms/step - loss: 0.1175 - accuracy: 0.9513\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 4s 124ms/step - loss: 0.1109 - accuracy: 0.9600\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 4s 123ms/step - loss: 0.1319 - accuracy: 0.9463\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 4s 121ms/step - loss: 0.0992 - accuracy: 0.9575\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 4s 122ms/step - loss: 0.0941 - accuracy: 0.9600\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 4s 121ms/step - loss: 0.0869 - accuracy: 0.9638\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 4s 122ms/step - loss: 0.0759 - accuracy: 0.9737\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 4s 123ms/step - loss: 0.1233 - accuracy: 0.9575\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 4s 123ms/step - loss: 0.1157 - accuracy: 0.9538\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 4s 121ms/step - loss: 0.1150 - accuracy: 0.9588\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 4s 121ms/step - loss: 0.1156 - accuracy: 0.9625\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 4s 122ms/step - loss: 0.0848 - accuracy: 0.9650\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 4s 124ms/step - loss: 0.1094 - accuracy: 0.9638\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 4s 123ms/step - loss: 0.1026 - accuracy: 0.9500\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 4s 123ms/step - loss: 0.1542 - accuracy: 0.9388\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 4s 124ms/step - loss: 0.1884 - accuracy: 0.9375\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 4s 123ms/step - loss: 0.1278 - accuracy: 0.9588\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 4s 123ms/step - loss: 0.0894 - accuracy: 0.9712\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 4s 123ms/step - loss: 0.0789 - accuracy: 0.9700\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 4s 124ms/step - loss: 0.0759 - accuracy: 0.9725\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 4s 124ms/step - loss: 0.0545 - accuracy: 0.9787\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 4s 123ms/step - loss: 0.0908 - accuracy: 0.9675\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 4s 123ms/step - loss: 0.0732 - accuracy: 0.9800\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 4s 123ms/step - loss: 0.0816 - accuracy: 0.9725\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 4s 123ms/step - loss: 0.0671 - accuracy: 0.9775\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 4s 125ms/step - loss: 0.0630 - accuracy: 0.9750\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 4s 123ms/step - loss: 0.0745 - accuracy: 0.9712\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 4s 124ms/step - loss: 0.0635 - accuracy: 0.9737\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 4s 123ms/step - loss: 0.0777 - accuracy: 0.9700\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 4s 123ms/step - loss: 0.0786 - accuracy: 0.9725\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 4s 123ms/step - loss: 0.0621 - accuracy: 0.9750\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 4s 124ms/step - loss: 0.0863 - accuracy: 0.9688\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 4s 122ms/step - loss: 0.2167 - accuracy: 0.9250\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 4s 122ms/step - loss: 0.0894 - accuracy: 0.9650\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 4s 122ms/step - loss: 0.0799 - accuracy: 0.9700\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 4s 123ms/step - loss: 0.0850 - accuracy: 0.9712\n",
      "7/7 [==============================] - 1s 34ms/step - loss: 0.6525 - accuracy: 0.8300\n",
      "Test Loss: 0.6525384783744812\n",
      "Test Accuracy: 82.99999833106995\n"
     ]
    }
   ],
   "source": [
    "# Define the hybrid CNN-RNN model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Reshape((128, 1)))  # Add a Reshape layer to convert to 3D\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=26)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy*100)\n",
    "model.save('CNN-RNN_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323cd5cc",
   "metadata": {},
   "source": [
    "# CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "2b4a454e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "54/54 [==============================] - 1s 2ms/step - loss: 0.5703 - accuracy: 0.7013\n",
      "Epoch 2/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.8150\n",
      "Epoch 3/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8575\n",
      "Epoch 4/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8800\n",
      "Epoch 5/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.8737\n",
      "Epoch 6/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.3034 - accuracy: 0.8888\n",
      "Epoch 7/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2930 - accuracy: 0.8888\n",
      "Epoch 8/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2757 - accuracy: 0.8963\n",
      "Epoch 9/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2631 - accuracy: 0.8950\n",
      "Epoch 10/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2603 - accuracy: 0.8988\n",
      "Epoch 11/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2474 - accuracy: 0.8975\n",
      "Epoch 12/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2423 - accuracy: 0.8988\n",
      "Epoch 13/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2294 - accuracy: 0.9137\n",
      "Epoch 14/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2430 - accuracy: 0.9000\n",
      "Epoch 15/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2282 - accuracy: 0.9112\n",
      "Epoch 16/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2190 - accuracy: 0.9137\n",
      "Epoch 17/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2081 - accuracy: 0.9200\n",
      "Epoch 18/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2093 - accuracy: 0.9150\n",
      "Epoch 19/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2076 - accuracy: 0.9150\n",
      "Epoch 20/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2021 - accuracy: 0.9137\n",
      "Epoch 21/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1896 - accuracy: 0.9225\n",
      "Epoch 22/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.1856 - accuracy: 0.9287\n",
      "Epoch 23/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.1843 - accuracy: 0.9287\n",
      "Epoch 24/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2031 - accuracy: 0.9275\n",
      "Epoch 25/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1633 - accuracy: 0.9388\n",
      "Epoch 26/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.1800 - accuracy: 0.9212\n",
      "Epoch 27/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.1703 - accuracy: 0.9337\n",
      "Epoch 28/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1643 - accuracy: 0.9375\n",
      "Epoch 29/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.1413 - accuracy: 0.9525\n",
      "Epoch 30/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.1521 - accuracy: 0.9375\n",
      "Epoch 31/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.1541 - accuracy: 0.9425\n",
      "Epoch 32/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.1317 - accuracy: 0.9550\n",
      "Epoch 33/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.1276 - accuracy: 0.9475\n",
      "Epoch 34/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.1305 - accuracy: 0.9500\n",
      "Epoch 35/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.1161 - accuracy: 0.9563\n",
      "Epoch 36/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.1248 - accuracy: 0.9525\n",
      "Epoch 37/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.1166 - accuracy: 0.9625\n",
      "Epoch 38/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0994 - accuracy: 0.9663\n",
      "Epoch 39/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0985 - accuracy: 0.9600\n",
      "Epoch 40/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0920 - accuracy: 0.9737\n",
      "Epoch 41/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0806 - accuracy: 0.9762\n",
      "Epoch 42/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1159 - accuracy: 0.9575\n",
      "Epoch 43/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0883 - accuracy: 0.9725\n",
      "Epoch 44/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0951 - accuracy: 0.9712\n",
      "Epoch 45/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0741 - accuracy: 0.9775\n",
      "Epoch 46/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.9812\n",
      "Epoch 47/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0715 - accuracy: 0.9775\n",
      "Epoch 48/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.9837\n",
      "Epoch 49/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0578 - accuracy: 0.9862\n",
      "Epoch 50/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0823 - accuracy: 0.9688\n",
      "Epoch 51/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0563 - accuracy: 0.9825\n",
      "Epoch 52/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0417 - accuracy: 0.9900\n",
      "Epoch 53/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9925\n",
      "Epoch 54/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0556 - accuracy: 0.9800\n",
      "Epoch 55/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.1343 - accuracy: 0.9450\n",
      "Epoch 56/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0442 - accuracy: 0.9875\n",
      "Epoch 57/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.9962\n",
      "Epoch 58/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0266 - accuracy: 0.9962\n",
      "Epoch 59/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0264 - accuracy: 0.9962\n",
      "Epoch 60/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.9925\n",
      "Epoch 61/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 0.9950\n",
      "Epoch 62/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0232 - accuracy: 0.9937\n",
      "Epoch 63/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0200 - accuracy: 0.9975\n",
      "Epoch 64/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 0.9987\n",
      "Epoch 65/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 0.9975\n",
      "Epoch 66/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 0.9987\n",
      "Epoch 67/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 0.9987\n",
      "Epoch 68/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0127 - accuracy: 0.9975\n",
      "Epoch 69/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 0.9975\n",
      "Epoch 70/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 71/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 0.9987\n",
      "Epoch 72/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 73/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 74/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 75/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 76/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 0.9987\n",
      "Epoch 77/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0594 - accuracy: 0.9837\n",
      "Epoch 78/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.1936 - accuracy: 0.9413\n",
      "Epoch 79/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0449 - accuracy: 0.9862\n",
      "Epoch 80/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 0.9987\n",
      "Epoch 81/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 0.9987\n",
      "Epoch 82/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 84/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 85/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 86/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 96/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 9.8309e-04 - accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 9.8851e-04 - accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 9.0212e-04 - accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 8.7892e-04 - accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 8.0529e-04 - accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 7.8832e-04 - accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 7.5252e-04 - accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 7.2172e-04 - accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 7.0932e-04 - accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 6.7254e-04 - accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 6.4110e-04 - accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 5.8934e-04 - accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 5.5413e-04 - accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 5.4281e-04 - accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 5.2274e-04 - accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 6.0521e-04 - accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 4.8945e-04 - accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 4.4771e-04 - accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 4.3888e-04 - accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 4.3387e-04 - accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.9418e-04 - accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.7170e-04 - accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.6894e-04 - accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.5136e-04 - accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.3385e-04 - accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.4692e-04 - accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3.0704e-04 - accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 2.8766e-04 - accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 2.9512e-04 - accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 2.7840e-04 - accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 2.6038e-04 - accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 2.4307e-04 - accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 2.3530e-04 - accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 2.3042e-04 - accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 2.1805e-04 - accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 2.1472e-04 - accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 2.0218e-04 - accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 1.9235e-04 - accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 1.8782e-04 - accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 1.8530e-04 - accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 1.7430e-04 - accuracy: 1.0000\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8396 - accuracy: 0.8150\n",
      "Test Loss: 1.8396204710006714\n",
      "Test Accuracy: 81.49999976158142\n",
      "7/7 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=15)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy*100)\n",
    "\n",
    "# Predict on new data\n",
    "predictions = model.predict(X_test)\n",
    "model.save('CNNmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "a1567906",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 2.8945e-04 - accuracy: 1.0000 - val_loss: 1.5800 - val_accuracy: 0.8400\n",
      "Epoch 2/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 2.7681e-04 - accuracy: 1.0000 - val_loss: 1.5948 - val_accuracy: 0.8400\n",
      "Epoch 3/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 2.6486e-04 - accuracy: 1.0000 - val_loss: 1.6067 - val_accuracy: 0.8400\n",
      "Epoch 4/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 2.5016e-04 - accuracy: 1.0000 - val_loss: 1.6066 - val_accuracy: 0.8400\n",
      "Epoch 5/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 2.4763e-04 - accuracy: 1.0000 - val_loss: 1.6193 - val_accuracy: 0.8400\n",
      "Epoch 6/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 2.3747e-04 - accuracy: 1.0000 - val_loss: 1.6528 - val_accuracy: 0.8450\n",
      "Epoch 7/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 2.3388e-04 - accuracy: 1.0000 - val_loss: 1.6376 - val_accuracy: 0.8400\n",
      "Epoch 8/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 2.2442e-04 - accuracy: 1.0000 - val_loss: 1.6302 - val_accuracy: 0.8400\n",
      "Epoch 9/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 2.2217e-04 - accuracy: 1.0000 - val_loss: 1.6301 - val_accuracy: 0.8400\n",
      "Epoch 10/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 2.0775e-04 - accuracy: 1.0000 - val_loss: 1.6548 - val_accuracy: 0.8400\n",
      "Epoch 11/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.9469e-04 - accuracy: 1.0000 - val_loss: 1.6634 - val_accuracy: 0.8500\n",
      "Epoch 12/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.9588e-04 - accuracy: 1.0000 - val_loss: 1.6588 - val_accuracy: 0.8400\n",
      "Epoch 13/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.8250e-04 - accuracy: 1.0000 - val_loss: 1.6737 - val_accuracy: 0.8400\n",
      "Epoch 14/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.7499e-04 - accuracy: 1.0000 - val_loss: 1.6726 - val_accuracy: 0.8400\n",
      "Epoch 15/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.7745e-04 - accuracy: 1.0000 - val_loss: 1.6642 - val_accuracy: 0.8400\n",
      "Epoch 16/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.6637e-04 - accuracy: 1.0000 - val_loss: 1.6821 - val_accuracy: 0.8400\n",
      "Epoch 17/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.6424e-04 - accuracy: 1.0000 - val_loss: 1.6801 - val_accuracy: 0.8400\n",
      "Epoch 18/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.5388e-04 - accuracy: 1.0000 - val_loss: 1.6996 - val_accuracy: 0.8400\n",
      "Epoch 19/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.5286e-04 - accuracy: 1.0000 - val_loss: 1.7065 - val_accuracy: 0.8450\n",
      "Epoch 20/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.4595e-04 - accuracy: 1.0000 - val_loss: 1.6853 - val_accuracy: 0.8400\n",
      "Epoch 21/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.4909e-04 - accuracy: 1.0000 - val_loss: 1.7240 - val_accuracy: 0.8450\n",
      "Epoch 22/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.6776e-04 - accuracy: 1.0000 - val_loss: 1.7634 - val_accuracy: 0.8400\n",
      "Epoch 23/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.4196e-04 - accuracy: 1.0000 - val_loss: 1.7534 - val_accuracy: 0.8500\n",
      "Epoch 24/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.3680e-04 - accuracy: 1.0000 - val_loss: 1.7247 - val_accuracy: 0.8400\n",
      "Epoch 25/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.2278e-04 - accuracy: 1.0000 - val_loss: 1.7212 - val_accuracy: 0.8400\n",
      "Epoch 26/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1679e-04 - accuracy: 1.0000 - val_loss: 1.7545 - val_accuracy: 0.8450\n",
      "Epoch 27/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1306e-04 - accuracy: 1.0000 - val_loss: 1.7595 - val_accuracy: 0.8500\n",
      "Epoch 28/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0972e-04 - accuracy: 1.0000 - val_loss: 1.7648 - val_accuracy: 0.8500\n",
      "Epoch 29/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0647e-04 - accuracy: 1.0000 - val_loss: 1.7705 - val_accuracy: 0.8450\n",
      "Epoch 30/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0279e-04 - accuracy: 1.0000 - val_loss: 1.7594 - val_accuracy: 0.8450\n",
      "Epoch 31/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 9.8923e-05 - accuracy: 1.0000 - val_loss: 1.7885 - val_accuracy: 0.8500\n",
      "Epoch 32/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 9.7458e-05 - accuracy: 1.0000 - val_loss: 1.7877 - val_accuracy: 0.8450\n",
      "Epoch 33/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 9.4077e-05 - accuracy: 1.0000 - val_loss: 1.7736 - val_accuracy: 0.8450\n",
      "Epoch 34/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 9.0306e-05 - accuracy: 1.0000 - val_loss: 1.7942 - val_accuracy: 0.8450\n",
      "Epoch 35/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 8.7604e-05 - accuracy: 1.0000 - val_loss: 1.7793 - val_accuracy: 0.8450\n",
      "Epoch 36/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 8.6000e-05 - accuracy: 1.0000 - val_loss: 1.8196 - val_accuracy: 0.8450\n",
      "Epoch 37/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 7.8839e-05 - accuracy: 1.0000 - val_loss: 1.7959 - val_accuracy: 0.8450\n",
      "Epoch 38/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 7.9374e-05 - accuracy: 1.0000 - val_loss: 1.8263 - val_accuracy: 0.8450\n",
      "Epoch 39/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 7.5935e-05 - accuracy: 1.0000 - val_loss: 1.8102 - val_accuracy: 0.8450\n",
      "Epoch 40/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 7.2487e-05 - accuracy: 1.0000 - val_loss: 1.8479 - val_accuracy: 0.8450\n",
      "Epoch 41/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 8.0318e-05 - accuracy: 1.0000 - val_loss: 1.8150 - val_accuracy: 0.8450\n",
      "Epoch 42/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 7.0631e-05 - accuracy: 1.0000 - val_loss: 1.8335 - val_accuracy: 0.8450\n",
      "Epoch 43/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 6.6643e-05 - accuracy: 1.0000 - val_loss: 1.8685 - val_accuracy: 0.8450\n",
      "Epoch 44/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 6.6859e-05 - accuracy: 1.0000 - val_loss: 1.8674 - val_accuracy: 0.8500\n",
      "Epoch 45/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 6.1288e-05 - accuracy: 1.0000 - val_loss: 1.8776 - val_accuracy: 0.8500\n",
      "Epoch 46/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 5.9412e-05 - accuracy: 1.0000 - val_loss: 1.8429 - val_accuracy: 0.8450\n",
      "Epoch 47/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 6.0546e-05 - accuracy: 1.0000 - val_loss: 1.8795 - val_accuracy: 0.8450\n",
      "Epoch 48/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 5.7452e-05 - accuracy: 1.0000 - val_loss: 1.8633 - val_accuracy: 0.8450\n",
      "Epoch 49/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 5.4992e-05 - accuracy: 1.0000 - val_loss: 1.8747 - val_accuracy: 0.8450\n",
      "Epoch 50/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 5.3025e-05 - accuracy: 1.0000 - val_loss: 1.8886 - val_accuracy: 0.8450\n",
      "Epoch 51/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 5.4263e-05 - accuracy: 1.0000 - val_loss: 1.8890 - val_accuracy: 0.8450\n",
      "Epoch 52/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 4.8560e-05 - accuracy: 1.0000 - val_loss: 1.8889 - val_accuracy: 0.8450\n",
      "Epoch 53/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 4.7213e-05 - accuracy: 1.0000 - val_loss: 1.8986 - val_accuracy: 0.8450\n",
      "Epoch 54/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 4.9247e-05 - accuracy: 1.0000 - val_loss: 1.9170 - val_accuracy: 0.8400\n",
      "Epoch 55/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 5.1633e-05 - accuracy: 1.0000 - val_loss: 1.8770 - val_accuracy: 0.8450\n",
      "Epoch 56/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 4.6704e-05 - accuracy: 1.0000 - val_loss: 1.8942 - val_accuracy: 0.8450\n",
      "Epoch 57/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 4.4087e-05 - accuracy: 1.0000 - val_loss: 1.9072 - val_accuracy: 0.8450\n",
      "Epoch 58/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 4.3238e-05 - accuracy: 1.0000 - val_loss: 1.9160 - val_accuracy: 0.8450\n",
      "Epoch 59/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 4.0050e-05 - accuracy: 1.0000 - val_loss: 1.9587 - val_accuracy: 0.8450\n",
      "Epoch 60/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.8911e-05 - accuracy: 1.0000 - val_loss: 1.9462 - val_accuracy: 0.8450\n",
      "Epoch 61/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.7065e-05 - accuracy: 1.0000 - val_loss: 1.9476 - val_accuracy: 0.8450\n",
      "Epoch 62/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6267e-05 - accuracy: 1.0000 - val_loss: 1.9446 - val_accuracy: 0.8450\n",
      "Epoch 63/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.5429e-05 - accuracy: 1.0000 - val_loss: 1.9502 - val_accuracy: 0.8450\n",
      "Epoch 64/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.5133e-05 - accuracy: 1.0000 - val_loss: 1.9465 - val_accuracy: 0.8450\n",
      "Epoch 65/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.3472e-05 - accuracy: 1.0000 - val_loss: 1.9885 - val_accuracy: 0.8500\n",
      "Epoch 66/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.3704e-05 - accuracy: 1.0000 - val_loss: 1.9807 - val_accuracy: 0.8450\n",
      "Epoch 67/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.1325e-05 - accuracy: 1.0000 - val_loss: 1.9861 - val_accuracy: 0.8450\n",
      "Epoch 68/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.0557e-05 - accuracy: 1.0000 - val_loss: 2.0039 - val_accuracy: 0.8450\n",
      "Epoch 69/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 2.9471e-05 - accuracy: 1.0000 - val_loss: 2.0012 - val_accuracy: 0.8450\n",
      "Epoch 70/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 2.8211e-05 - accuracy: 1.0000 - val_loss: 1.9932 - val_accuracy: 0.8500\n",
      "Epoch 71/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 2.7932e-05 - accuracy: 1.0000 - val_loss: 1.9858 - val_accuracy: 0.8400\n",
      "Epoch 72/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 2.6304e-05 - accuracy: 1.0000 - val_loss: 2.0376 - val_accuracy: 0.8450\n",
      "Epoch 73/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 2.5096e-05 - accuracy: 1.0000 - val_loss: 2.0112 - val_accuracy: 0.8400\n",
      "Epoch 74/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 2.4329e-05 - accuracy: 1.0000 - val_loss: 2.0040 - val_accuracy: 0.8450\n",
      "Epoch 75/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 2.3727e-05 - accuracy: 1.0000 - val_loss: 2.0324 - val_accuracy: 0.8450\n",
      "Epoch 76/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 2.2943e-05 - accuracy: 1.0000 - val_loss: 2.0427 - val_accuracy: 0.8450\n",
      "Epoch 77/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 2.2154e-05 - accuracy: 1.0000 - val_loss: 2.0495 - val_accuracy: 0.8450\n",
      "Epoch 78/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 2.1288e-05 - accuracy: 1.0000 - val_loss: 2.0559 - val_accuracy: 0.8450\n",
      "Epoch 79/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 2.0430e-05 - accuracy: 1.0000 - val_loss: 2.0515 - val_accuracy: 0.8450\n",
      "Epoch 80/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.9806e-05 - accuracy: 1.0000 - val_loss: 2.0772 - val_accuracy: 0.8450\n",
      "Epoch 81/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.9045e-05 - accuracy: 1.0000 - val_loss: 2.0744 - val_accuracy: 0.8450\n",
      "Epoch 82/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.8528e-05 - accuracy: 1.0000 - val_loss: 2.0704 - val_accuracy: 0.8450\n",
      "Epoch 83/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.8157e-05 - accuracy: 1.0000 - val_loss: 2.0551 - val_accuracy: 0.8450\n",
      "Epoch 84/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.8573e-05 - accuracy: 1.0000 - val_loss: 2.0932 - val_accuracy: 0.8400\n",
      "Epoch 85/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.7616e-05 - accuracy: 1.0000 - val_loss: 2.0700 - val_accuracy: 0.8400\n",
      "Epoch 86/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.7138e-05 - accuracy: 1.0000 - val_loss: 2.0799 - val_accuracy: 0.8400\n",
      "Epoch 87/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.5947e-05 - accuracy: 1.0000 - val_loss: 2.0960 - val_accuracy: 0.8450\n",
      "Epoch 88/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.5316e-05 - accuracy: 1.0000 - val_loss: 2.1083 - val_accuracy: 0.8450\n",
      "Epoch 89/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.5005e-05 - accuracy: 1.0000 - val_loss: 2.1285 - val_accuracy: 0.8450\n",
      "Epoch 90/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.4546e-05 - accuracy: 1.0000 - val_loss: 2.1089 - val_accuracy: 0.8450\n",
      "Epoch 91/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.4022e-05 - accuracy: 1.0000 - val_loss: 2.1377 - val_accuracy: 0.8500\n",
      "Epoch 92/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.3438e-05 - accuracy: 1.0000 - val_loss: 2.1798 - val_accuracy: 0.8450\n",
      "Epoch 93/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.4150e-05 - accuracy: 1.0000 - val_loss: 2.1198 - val_accuracy: 0.8450\n",
      "Epoch 94/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.2989e-05 - accuracy: 1.0000 - val_loss: 2.1627 - val_accuracy: 0.8450\n",
      "Epoch 95/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.2970e-05 - accuracy: 1.0000 - val_loss: 2.1686 - val_accuracy: 0.8450\n",
      "Epoch 96/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1929e-05 - accuracy: 1.0000 - val_loss: 2.1788 - val_accuracy: 0.8500\n",
      "Epoch 97/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.2304e-05 - accuracy: 1.0000 - val_loss: 2.1510 - val_accuracy: 0.8450\n",
      "Epoch 98/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1724e-05 - accuracy: 1.0000 - val_loss: 2.1517 - val_accuracy: 0.8400\n",
      "Epoch 99/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1596e-05 - accuracy: 1.0000 - val_loss: 2.1572 - val_accuracy: 0.8400\n",
      "Epoch 100/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0556e-05 - accuracy: 1.0000 - val_loss: 2.1890 - val_accuracy: 0.8400\n",
      "Epoch 101/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0360e-05 - accuracy: 1.0000 - val_loss: 2.1896 - val_accuracy: 0.8450\n",
      "Epoch 102/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 9.7754e-06 - accuracy: 1.0000 - val_loss: 2.1922 - val_accuracy: 0.8400\n",
      "Epoch 103/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 9.6964e-06 - accuracy: 1.0000 - val_loss: 2.2076 - val_accuracy: 0.8400\n",
      "Epoch 104/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 9.1009e-06 - accuracy: 1.0000 - val_loss: 2.2102 - val_accuracy: 0.8400\n",
      "Epoch 105/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 8.9855e-06 - accuracy: 1.0000 - val_loss: 2.2090 - val_accuracy: 0.8400\n",
      "Epoch 106/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 9.7827e-06 - accuracy: 1.0000 - val_loss: 2.2379 - val_accuracy: 0.8450\n",
      "Epoch 107/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 8.7656e-06 - accuracy: 1.0000 - val_loss: 2.2275 - val_accuracy: 0.8450\n",
      "Epoch 108/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 8.0948e-06 - accuracy: 1.0000 - val_loss: 2.2042 - val_accuracy: 0.8400\n",
      "Epoch 109/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 8.2754e-06 - accuracy: 1.0000 - val_loss: 2.2334 - val_accuracy: 0.8400\n",
      "Epoch 110/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 7.6845e-06 - accuracy: 1.0000 - val_loss: 2.2455 - val_accuracy: 0.8450\n",
      "Epoch 111/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 7.3439e-06 - accuracy: 1.0000 - val_loss: 2.2295 - val_accuracy: 0.8450\n",
      "Epoch 112/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 6.9926e-06 - accuracy: 1.0000 - val_loss: 2.2559 - val_accuracy: 0.8400\n",
      "Epoch 113/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 0s 3ms/step - loss: 7.0349e-06 - accuracy: 1.0000 - val_loss: 2.2624 - val_accuracy: 0.8450\n",
      "Epoch 114/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 6.6488e-06 - accuracy: 1.0000 - val_loss: 2.2802 - val_accuracy: 0.8450\n",
      "Epoch 115/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 6.4997e-06 - accuracy: 1.0000 - val_loss: 2.2739 - val_accuracy: 0.8450\n",
      "Epoch 116/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 6.2265e-06 - accuracy: 1.0000 - val_loss: 2.2529 - val_accuracy: 0.8400\n",
      "Epoch 117/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 6.3648e-06 - accuracy: 1.0000 - val_loss: 2.3126 - val_accuracy: 0.8450\n",
      "Epoch 118/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 6.2428e-06 - accuracy: 1.0000 - val_loss: 2.2973 - val_accuracy: 0.8400\n",
      "Epoch 119/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 6.0105e-06 - accuracy: 1.0000 - val_loss: 2.2784 - val_accuracy: 0.8450\n",
      "Epoch 120/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 5.5928e-06 - accuracy: 1.0000 - val_loss: 2.3002 - val_accuracy: 0.8400\n",
      "Epoch 121/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 5.4678e-06 - accuracy: 1.0000 - val_loss: 2.3102 - val_accuracy: 0.8450\n",
      "Epoch 122/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 5.2390e-06 - accuracy: 1.0000 - val_loss: 2.2985 - val_accuracy: 0.8350\n",
      "Epoch 123/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 5.4855e-06 - accuracy: 1.0000 - val_loss: 2.2863 - val_accuracy: 0.8400\n",
      "Epoch 124/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 5.2699e-06 - accuracy: 1.0000 - val_loss: 2.3372 - val_accuracy: 0.8450\n",
      "Epoch 125/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 4.7343e-06 - accuracy: 1.0000 - val_loss: 2.3267 - val_accuracy: 0.8450\n",
      "Epoch 126/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 4.5775e-06 - accuracy: 1.0000 - val_loss: 2.3413 - val_accuracy: 0.8450\n",
      "Epoch 127/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 4.5991e-06 - accuracy: 1.0000 - val_loss: 2.3295 - val_accuracy: 0.8350\n",
      "Epoch 128/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 4.4002e-06 - accuracy: 1.0000 - val_loss: 2.3519 - val_accuracy: 0.8450\n",
      "Epoch 129/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 4.1088e-06 - accuracy: 1.0000 - val_loss: 2.3380 - val_accuracy: 0.8400\n",
      "Epoch 130/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 4.2908e-06 - accuracy: 1.0000 - val_loss: 2.3411 - val_accuracy: 0.8400\n",
      "Epoch 131/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 4.2637e-06 - accuracy: 1.0000 - val_loss: 2.3524 - val_accuracy: 0.8400\n",
      "Epoch 132/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6760e-06 - accuracy: 1.0000 - val_loss: 2.3525 - val_accuracy: 0.8400\n",
      "Epoch 133/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.8645e-06 - accuracy: 1.0000 - val_loss: 2.3654 - val_accuracy: 0.8400\n",
      "Epoch 134/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.5345e-06 - accuracy: 1.0000 - val_loss: 2.3720 - val_accuracy: 0.8400\n",
      "Epoch 135/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.5068e-06 - accuracy: 1.0000 - val_loss: 2.3912 - val_accuracy: 0.8450\n",
      "Epoch 136/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.2405e-06 - accuracy: 1.0000 - val_loss: 2.4118 - val_accuracy: 0.8450\n",
      "Epoch 137/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.3336e-06 - accuracy: 1.0000 - val_loss: 2.4083 - val_accuracy: 0.8400\n",
      "Epoch 138/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.1401e-06 - accuracy: 1.0000 - val_loss: 2.4019 - val_accuracy: 0.8400\n",
      "Epoch 139/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.2092e-06 - accuracy: 1.0000 - val_loss: 2.3979 - val_accuracy: 0.8400\n",
      "Epoch 140/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 2.9538e-06 - accuracy: 1.0000 - val_loss: 2.4238 - val_accuracy: 0.8450\n",
      "Epoch 141/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 2.8304e-06 - accuracy: 1.0000 - val_loss: 2.3949 - val_accuracy: 0.8400\n",
      "Epoch 142/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 2.7020e-06 - accuracy: 1.0000 - val_loss: 2.4385 - val_accuracy: 0.8450\n",
      "Epoch 143/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 2.7637e-06 - accuracy: 1.0000 - val_loss: 2.4542 - val_accuracy: 0.8450\n",
      "Epoch 144/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 2.5624e-06 - accuracy: 1.0000 - val_loss: 2.4404 - val_accuracy: 0.8400\n",
      "Epoch 145/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 2.4861e-06 - accuracy: 1.0000 - val_loss: 2.4742 - val_accuracy: 0.8450\n",
      "Epoch 146/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 2.4290e-06 - accuracy: 1.0000 - val_loss: 2.4871 - val_accuracy: 0.8450\n",
      "Epoch 147/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 2.4335e-06 - accuracy: 1.0000 - val_loss: 2.4472 - val_accuracy: 0.8400\n",
      "Epoch 148/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 2.4058e-06 - accuracy: 1.0000 - val_loss: 2.4548 - val_accuracy: 0.8400\n",
      "Epoch 149/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 2.2199e-06 - accuracy: 1.0000 - val_loss: 2.4679 - val_accuracy: 0.8450\n",
      "Epoch 150/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 2.1249e-06 - accuracy: 1.0000 - val_loss: 2.4835 - val_accuracy: 0.8450\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkkAAAHFCAYAAADmGm0KAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABu7UlEQVR4nO3dd1gUx/8H8PfROyIoRRSwAtYINuwNxJ5oosaCscdYiKYZY6LG2BLLN1HJLwbsETWWmMSGvYCiKMYWxYoKhEAUVBQQ9vfHesstt5RT9ADfr+e5B252dnfm2n52ZnZWJQiCACIiIiKSMdB3AYiIiIhKIwZJRERERAoYJBEREREpYJBEREREpIBBEhEREZECBklEREREChgkERERESlgkERERESkgEESERERkQIGSfTaUqlUxXocPHjwhfYzffp0qFSq51r34MGDJVKG0m7o0KFwd3cvcPm///4LExMT9O/fv8A86enpsLCwQM+ePYu935UrV0KlUuHmzZvFLosmlUqF6dOnF3t/agkJCZg+fTpiY2O1lr3I56WkZGdnw8nJCSqVCr/++qtey0KkT0b6LgCRvkRFRcmef/311zhw4AD2798vS/f29n6h/YwYMQJdunR5rnUbN26MqKioFy5DWVepUiX07NkT27Ztw71792BnZ6eVJzw8HI8fP8bw4cNfaF/Tpk3DxIkTX2gbRUlISMCMGTPg7u6ORo0ayZa9yOelpPzxxx/4559/AAChoaHo27evXstDpC8Mkui11bx5c9nzSpUqwcDAQCs9v4yMDFhYWBR7P66urnB1dX2uMtrY2BRZntfF8OHDsXnzZqxbtw7jxo3TWh4WFgZHR0d069bthfZTo0aNF1r/Rb3I56WkhIaGwsTEBG3btsWePXtw584dvZdJSU5ODp4+fQpTU1N9F4XKKXa3ERWiXbt2qFevHg4fPgw/Pz9YWFhg2LBhAIANGzbA398fzs7OMDc3h5eXFz777DM8evRItg2l7hN3d3d0794du3btQuPGjWFubg5PT0+EhYXJ8il1tw0dOhRWVla4evUqunbtCisrK1StWhWTJ09GZmambP07d+6gb9++sLa2RoUKFTBw4ECcPHkSKpUKK1euLLTu//77L8aOHQtvb29YWVmhcuXK6NChA44cOSLLd/PmTahUKnz33XdYuHAhPDw8YGVlhRYtWuD48eNa2125ciXq1KkDU1NTeHl5YfXq1YWWQy0gIACurq5YsWKF1rJLly7hxIkTGDJkCIyMjBAREYFevXrB1dUVZmZmqFmzJkaPHo2UlJQi96PU3Zaeno6RI0fC3t4eVlZW6NKlC65cuaK17tWrV/Hee++hVq1asLCwQJUqVdCjRw+cO3dOynPw4EE0adIEAPDee+9J3brqbjulz0tubi7mz58PT09PmJqaonLlyhgyZAju3Lkjy6f+vJ48eRKtW7eGhYUFqlevjrlz5yI3N7fIugNiK9euXbvQo0cPfPzxx8jNzS3ws/LLL7+gRYsWsLKygpWVFRo1aoTQ0FBZnl27dqFjx46wtbWFhYUFvLy8MGfOHFmZ27Vrp7Xt/O+D+nM2f/58zJo1Cx4eHjA1NcWBAwfw5MkTTJ48GY0aNYKtrS0qVqyIFi1a4LffftPabm5uLn744Qc0atQI5ubmqFChApo3b47t27cDEIPxihUrIiMjQ2vdDh06oG7dusV4Fam8YJBEVITExEQMGjQI7777Lnbs2IGxY8cCAOLi4tC1a1eEhoZi165dCA4OxsaNG9GjR49ibffs2bOYPHkyPvzwQ/z2229o0KABhg8fjsOHDxe5bnZ2Nnr27ImOHTvit99+w7Bhw7Bo0SLMmzdPyvPo0SO0b98eBw4cwLx587Bx40Y4OjqiX79+xSrff//9BwD46quv8Oeff2LFihWoXr062rVrpzhGaunSpYiIiMDixYuxbt06PHr0CF27dkVaWpqUZ+XKlXjvvffg5eWFzZs344svvsDXX3+t1cWpxMDAAEOHDsXp06dx9uxZ2TJ14KQOYK9du4YWLVogJCQEe/bswZdffokTJ06gVatWyM7OLlb91QRBQO/evbFmzRpMnjwZW7duRfPmzREYGKiVNyEhAfb29pg7dy527dqFpUuXwsjICM2aNcPly5cBiF2o6vJ+8cUXiIqKQlRUFEaMGFFgGd5//318+umn6Ny5M7Zv346vv/4au3btgp+fn1bgl5SUhIEDB2LQoEHYvn07AgMDMWXKFKxdu7ZY9V25ciVycnIwbNgwdOrUCW5ubggLC4MgCLJ8X375JQYOHAgXFxesXLkSW7duRVBQEG7duiXlCQ0NRdeuXZGbm4sff/wRv//+OyZMmKAV3Oni+++/x/79+/Hdd99h586d8PT0RGZmJv777z989NFH2LZtG9avX49WrVrhrbfe0grChw4diokTJ6JJkybYsGEDwsPD0bNnT2lc2sSJE3Hv3j388ssvsvUuXryIAwcO4IMPPnjuslMZJBCRIAiCEBQUJFhaWsrS2rZtKwAQ9u3bV+i6ubm5QnZ2tnDo0CEBgHD27Flp2VdffSXk/6q5ubkJZmZmwq1bt6S0x48fCxUrVhRGjx4tpR04cEAAIBw4cEBWTgDCxo0bZdvs2rWrUKdOHen50qVLBQDCzp07ZflGjx4tABBWrFhRaJ3ye/r0qZCdnS107NhRePPNN6X0GzduCACE+vXrC0+fPpXSo6OjBQDC+vXrBUEQhJycHMHFxUVo3LixkJubK+W7efOmYGxsLLi5uRVZhuvXrwsqlUqYMGGClJadnS04OTkJLVu2VFxH/d7cunVLACD89ttv0rIVK1YIAIQbN25IaUFBQbKy7Ny5UwAg/O9//5Nt95tvvhEACF999VWB5X369KmQlZUl1KpVS/jwww+l9JMnTxb4HuT/vFy6dEkAIIwdO1aW78SJEwIA4fPPP5fS1J/XEydOyPJ6e3sLAQEBBZZTLTc3V6hZs6ZQpUoV6b1Ul0fzO3D9+nXB0NBQGDhwYIHbevDggWBjYyO0atVK9n7n17ZtW6Ft27Za6fnfB/XnrEaNGkJWVlah9VB/VocPHy688cYbUvrhw4cFAMLUqVMLXb9t27ZCo0aNZGnvv/++YGNjIzx48KDQdal8YUsSURHs7OzQoUMHrfTr16/j3XffhZOTEwwNDWFsbIy2bdsCELt/itKoUSNUq1ZNem5mZobatWvLzsQLolKptFqsGjRoIFv30KFDsLa21hoEPGDAgCK3r/bjjz+icePGMDMzg5GREYyNjbFv3z7F+nXr1g2Ghoay8gCQynT58mUkJCTg3XfflXUnubm5wc/Pr1jl8fDwQPv27bFu3TpkZWUBAHbu3ImkpCSpFQkAkpOTMWbMGFStWlUqt5ubG4DivTeaDhw4AAAYOHCgLP3dd9/Vyvv06VPMnj0b3t7eMDExgZGREUxMTBAXF6fzfvPvf+jQobL0pk2bwsvLC/v27ZOlOzk5oWnTprK0/J+Nghw6dAhXr15FUFCQ9F6quwQ1u4IjIiKQk5NTaKtKZGQk0tPTMXbs2BK9Wq9nz54wNjbWSt+0aRNatmwJKysr6T0PDQ2Vve47d+4EgCJbgyZOnIjY2FgcO3YMgNjdumbNGgQFBcHKyqrE6kKlH4MkoiI4OztrpT18+BCtW7fGiRMnMGvWLBw8eBAnT57Eli1bAACPHz8ucrv29vZaaaampsVa18LCAmZmZlrrPnnyRHqempoKR0dHrXWV0pQsXLgQ77//Ppo1a4bNmzfj+PHjOHnyJLp06aJYxvz1UQ+mVedNTU0FIB7E81NKK8jw4cORmpoqjSFZsWIFrKys8M477wAQx5z4+/tjy5Yt+OSTT7Bv3z5ER0dL46OK8/pqSk1NhZGRkVb9lMo8adIkTJs2Db1798bvv/+OEydO4OTJk2jYsKHO+9XcP6D8OXRxcZGWq73I50o9nujNN9/E/fv3cf/+fdja2qJVq1bYvHkz7t+/D0Acrwag0MHcxcnzPJRehy1btuCdd95BlSpVsHbtWkRFReHkyZMYNmyY7Dvx77//wtDQsMjPW69eveDu7o6lS5cCELsgHz16xK621xCvbiMqgtJZ8P79+5GQkICDBw9KrUcApINIaWBvb4/o6Git9KSkpGKtv3btWrRr1w4hISGy9AcPHjx3eQraf3HLBABvvfUW7OzsEBYWhrZt2+KPP/7AkCFDpDP88+fP4+zZs1i5ciWCgoKk9a5evfrc5X769ClSU1NlAYhSmdeuXYshQ4Zg9uzZsvSUlBRUqFDhufcPiGPj8gccCQkJcHBweK7t5peWlobNmzcDgDSwPL9ffvkFY8eORaVKlQCIFwZUrVpVMa9mnsKYmZnJxq2pFTTIXun7uHbtWnh4eGDDhg2y5fkvZKhUqRJycnKQlJSkGGypGRgY4IMPPsDnn3+OBQsWYNmyZejYsSPq1KlTaF2o/GFLEtFzUP8Q57/0+P/+7//0URxFbdu2xYMHD6QuBrXw8PBira9SqbTq99dff2nNL1VcderUgbOzM9avXy8bBHzr1i1ERkYWeztmZmZ49913sWfPHsybNw/Z2dmyrraSfm/at28PAFi3bp0sPf/AXvW+8+/3zz//xN27d2Vp+VvZCqPu6s0/8PrkyZO4dOkSOnbsWOQ2iuOXX37B48ePpfnC8j8cHBykLjd/f38YGhpqBdCa/Pz8YGtrix9//FFr0Lcmd3d3XLlyRRbQpKam6vSZUKlUMDExkQVISUlJWle3qQfbF1ZutREjRsDExAQDBw7E5cuXFaedoPKPLUlEz8HPzw92dnYYM2YMvvrqKxgbG2PdunVaV13pU1BQEBYtWoRBgwZh1qxZqFmzJnbu3Indu3cDEM+WC9O9e3d8/fXX+Oqrr9C2bVtcvnwZM2fOhIeHB54+fapzeQwMDPD1119jxIgRePPNNzFy5Ejcv38f06dP16m7DRC73JYuXYqFCxfC09NTNqbJ09MTNWrUwGeffQZBEFCxYkX8/vvviIiI0LnMgBgQtGnTBp988gkePXoEX19fHDt2DGvWrNHK2717d6xcuRKenp5o0KABYmJi8O2332q1ANWoUQPm5uZYt24dvLy8YGVlBRcXF7i4uGhts06dOhg1ahR++OEHGBgYIDAwEDdv3sS0adNQtWpVfPjhh89Vr/xCQ0NhZ2eHjz76SKsrFwCGDBmChQsX4uzZs2jYsCE+//xzfP3113j8+DEGDBgAW1tbXLx4ESkpKZgxYwasrKywYMECjBgxAp06dcLIkSPh6OiIq1ev4uzZs1iyZAkAYPDgwfi///s/DBo0CCNHjkRqairmz58PGxubYpe9e/fu2LJlC8aOHYu+ffvi9u3b+Prrr+Hs7Iy4uDgpX+vWrTF48GDMmjUL//zzD7p37w5TU1OcOXMGFhYWGD9+vJS3QoUKGDJkCEJCQuDm5lbsq1apnNHzwHGiUqOgq9vq1q2rmD8yMlJo0aKFYGFhIVSqVEkYMWKEcPr0aa2rlgq6uq1bt25a28x/pU9BV7flL2dB+4mPjxfeeustwcrKSrC2thb69Okj7NixQ+sqLyWZmZnCRx99JFSpUkUwMzMTGjduLGzbtq3Aq46+/fZbrW1A4eqvn3/+WahVq5ZgYmIi1K5dWwgLC9PaZnG88cYbAgBh/vz5WssuXrwodO7cWbC2thbs7OyEt99+W4iPj9cqT3GubhMEQbh//74wbNgwoUKFCoKFhYXQuXNn4e+//9ba3r1794Thw4cLlStXFiwsLIRWrVoJR44cUbyCa/369YKnp6dgbGws247S+5iTkyPMmzdPqF27tmBsbCw4ODgIgwYNEm7fvi3LV9DntajX9+zZswIAITg4uMA86vqOHz9eSlu9erXQpEkTwczMTLCyshLeeOMNrSv2duzYIbRt21awtLQULCwsBG9vb2HevHmyPKtWrRK8vLwEMzMzwdvbW9iwYYNOnzNBEIS5c+cK7u7ugqmpqeDl5SUsX768wNdy0aJFQr169QQTExPB1tZWaNGihfD7779rbfPgwYMCAGHu3LkFvi5UvqkEoZB2UCIqd2bPno0vvvgC8fHxpXIWZaLSYvLkyQgJCcHt27cVB8RT+cfuNqJyTN2l4enpiezsbOzfvx/ff/89Bg0axACJqADHjx/HlStXsGzZMowePZoB0muMLUlE5VhYWBgWLVqEmzdvIjMzE9WqVcO7776LL774AiYmJvouHlGppFKpYGFhga5du0pTTNDriUESERERkQJOAUBERESkgEESERERkQIGSUREREQKeHXbc8rNzUVCQgKsra1L9OaNRERE9PIIgoAHDx7AxcWlyEl1GSQ9p4SEhALvWURERESl2+3bt4ucCoVB0nOytrYGIL7IukyfT0RERPqTnp6OqlWrSsfxwjBIek7qLjYbGxsGSURERGVMcYbKcOA2ERERkQIGSUREREQKGCQRERERKWCQRERERKSAQRIRERGRAgZJRERERAoYJBEREREpYJBEREREpIBBEhEREZECBklERERECvQaJB0+fBg9evSAi4sLVCoVtm3bVuQ6hw4dgo+PD8zMzFC9enX8+OOPWnk2b94Mb29vmJqawtvbG1u3btXKs2zZMnh4eMDMzAw+Pj44cuRISVSJiIiIygm9BkmPHj1Cw4YNsWTJkmLlv3HjBrp27YrWrVvjzJkz+PzzzzFhwgRs3rxZyhMVFYV+/fph8ODBOHv2LAYPHox33nkHJ06ckPJs2LABwcHBmDp1Ks6cOYPWrVsjMDAQ8fHxJV5HIiIiKptUgiAI+i4EIN5obuvWrejdu3eBeT799FNs374dly5dktLGjBmDs2fPIioqCgDQr18/pKenY+fOnVKeLl26wM7ODuvXrwcANGvWDI0bN0ZISIiUx8vLC71798acOXOKVd709HTY2toiLS2tRG9wKwgCHmfnlNj2iIiIyjJzY8Ni3Yy2uHQ5fhuV2F5fgaioKPj7+8vSAgICEBoaiuzsbBgbGyMqKgoffvihVp7FixcDALKyshATE4PPPvtMlsff3x+RkZEF7jszMxOZmZnS8/T09BesjbLH2Tnw/nL3S9k2ERFRWXNxZgAsTPQTrpSpgdtJSUlwdHSUpTk6OuLp06dISUkpNE9SUhIAICUlBTk5OYXmUTJnzhzY2tpKj6pVq5ZElYiIiKiUKlMtSQC0mtzUvYWa6Up58qcVJ4+mKVOmYNKkSdLz9PT0lxIomRsb4uLMgBLfLhERUVlkbmyot32XqSDJyclJq7UnOTkZRkZGsLe3LzSPuuXIwcEBhoaGheZRYmpqClNT05KoRqFUKpXemhWJiIgoT5nqbmvRogUiIiJkaXv27IGvry+MjY0LzePn5wcAMDExgY+Pj1aeiIgIKQ8RERGRXpssHj58iKtXr0rPb9y4gdjYWFSsWBHVqlXDlClTcPfuXaxevRqAeCXbkiVLMGnSJIwcORJRUVEIDQ2VrloDgIkTJ6JNmzaYN28eevXqhd9++w179+7F0aNHpTyTJk3C4MGD4evrixYtWuCnn35CfHw8xowZ8+oqT0RERKWboEcHDhwQAGg9goKCBEEQhKCgIKFt27aydQ4ePCi88cYbgomJieDu7i6EhIRobXfTpk1CnTp1BGNjY8HT01PYvHmzVp6lS5cKbm5ugomJidC4cWPh0KFDOpU9LS1NACCkpaXptB4RERHpjy7H71IzT1JZ87LmSSIiIqKXR5fjd5kak0RERET0qjBIIiIiIlLAIImIiIhIAYMkIiIiIgUMkoiIiIgUMEgiIiIiUsAgiYiIiEgBgyQiIiIiBQySiIiIiBQwSCIiIiJSwCCJiIiISAGDJCIiIiIFDJKIiIiIFDBIIiIiIlLAIImIiIhIAYMkIiIiIgUMkoiIiIgUMEgiIiIiUsAgiYiIiEgBgyQiIiIiBQySiIiIiBQwSCIiIiJSwCCJiIiISAGDJCIiIiIFDJKIiIiIFDBIIiIiIlLAIImIiIhIAYMkIiIiIgUMkoiIiIgUMEgiIiIiUsAgiYiIiEgBgyQiIiIiBQySiIiIiBQwSCIiIiJSwCCJiIiISAGDJCIiIiIFDJKIiIiIFDBIIiIiIlLAIImIiIhIAYMkIiIiIgV6D5KWLVsGDw8PmJmZwcfHB0eOHCk0/9KlS+Hl5QVzc3PUqVMHq1evli1v164dVCqV1qNbt25SnunTp2std3Jyein1IyIiorLJSJ8737BhA4KDg7Fs2TK0bNkS//d//4fAwEBcvHgR1apV08ofEhKCKVOmYPny5WjSpAmio6MxcuRI2NnZoUePHgCALVu2ICsrS1onNTUVDRs2xNtvvy3bVt26dbF3717puaGh4UuqJREREZVFeg2SFi5ciOHDh2PEiBEAgMWLF2P37t0ICQnBnDlztPKvWbMGo0ePRr9+/QAA1atXx/HjxzFv3jwpSKpYsaJsnfDwcFhYWGgFSUZGRmw9IiIiogLprbstKysLMTEx8Pf3l6X7+/sjMjJScZ3MzEyYmZnJ0szNzREdHY3s7GzFdUJDQ9G/f39YWlrK0uPi4uDi4gIPDw/0798f169fL7S8mZmZSE9Plz2IiIio/NJbkJSSkoKcnBw4OjrK0h0dHZGUlKS4TkBAAH7++WfExMRAEAScOnUKYWFhyM7ORkpKilb+6OhonD9/XmqpUmvWrBlWr16N3bt3Y/ny5UhKSoKfnx9SU1MLLO+cOXNga2srPapWrfoctSYiIqKyQu8Dt1Uqley5IAhaaWrTpk1DYGAgmjdvDmNjY/Tq1QtDhw4FoDymKDQ0FPXq1UPTpk1l6YGBgejTpw/q16+PTp064c8//wQArFq1qsByTpkyBWlpadLj9u3bulSTiIiIyhi9BUkODg4wNDTUajVKTk7Wal1SMzc3R1hYGDIyMnDz5k3Ex8fD3d0d1tbWcHBwkOXNyMhAeHi4ViuSEktLS9SvXx9xcXEF5jE1NYWNjY3sQUREROWX3oIkExMT+Pj4ICIiQpYeEREBPz+/Qtc1NjaGq6srDA0NER4eju7du8PAQF6VjRs3IjMzE4MGDSqyLJmZmbh06RKcnZ11rwgRERGVS3q9um3SpEkYPHgwfH190aJFC/z000+Ij4/HmDFjAIhdXHfv3pXmQrpy5Qqio6PRrFkz3Lt3DwsXLsT58+cVu8lCQ0PRu3dv2Nvbay376KOP0KNHD1SrVg3JycmYNWsW0tPTERQU9HIrTERERGWGXoOkfv36ITU1FTNnzkRiYiLq1auHHTt2wM3NDQCQmJiI+Ph4KX9OTg4WLFiAy5cvw9jYGO3bt0dkZCTc3d1l271y5QqOHj2KPXv2KO73zp07GDBgAFJSUlCpUiU0b94cx48fl/ZLREREpBIEQdB3Icqi9PR02NraIi0tjeOTiIiIyghdjt96v7qNiIiIqDRikERERESkgEESERERkQIGSUREREQKGCQRERERKWCQRERERKSAQRIRERGRAgZJRERERAoYJBEREREpYJBEREREpIBBEhEREZECBklEREREChgkERERESlgkERERESkgEESERERkQIGSUREREQKGCQRERERKWCQRERERKSAQRIRERGRAgZJRERERAoYJBEREREpYJBEREREpIBBEhEREZECBklEREREChgkERERESlgkERERESkgEESERERkQIGSUREREQKGCQRERERKWCQRERERKSAQRIRERGRAgZJRERERAoYJBEREREpYJBEREREpIBBEhEREZECBklEREREChgkERERESlgkERERESkgEESERERkQK9B0nLli2Dh4cHzMzM4OPjgyNHjhSaf+nSpfDy8oK5uTnq1KmD1atXy5avXLkSKpVK6/HkyZMX2i8RERG9XvQaJG3YsAHBwcGYOnUqzpw5g9atWyMwMBDx8fGK+UNCQjBlyhRMnz4dFy5cwIwZM/DBBx/g999/l+WzsbFBYmKi7GFmZvbc+yUiIqLXj0oQBEFfO2/WrBkaN26MkJAQKc3Lywu9e/fGnDlztPL7+fmhZcuW+Pbbb6W04OBgnDp1CkePHgUgtiQFBwfj/v37JbZfJenp6bC1tUVaWhpsbGyKtQ4RERHply7Hb721JGVlZSEmJgb+/v6ydH9/f0RGRiquk5mZKWsRAgBzc3NER0cjOztbSnv48CHc3Nzg6uqK7t2748yZMy+0XyIiInr96C1ISklJQU5ODhwdHWXpjo6OSEpKUlwnICAAP//8M2JiYiAIAk6dOoWwsDBkZ2cjJSUFAODp6YmVK1di+/btWL9+PczMzNCyZUvExcU9934BMUBLT0+XPYiIiKj80vvAbZVKJXsuCIJWmtq0adMQGBiI5s2bw9jYGL169cLQoUMBAIaGhgCA5s2bY9CgQWjYsCFat26NjRs3onbt2vjhhx+ee78AMGfOHNja2kqPqlWr6lpVIiIiKkP0FiQ5ODjA0NBQq/UmOTlZq5VHzdzcHGFhYcjIyMDNmzcRHx8Pd3d3WFtbw8HBQXEdAwMDNGnSRGpJep79AsCUKVOQlpYmPW7fvq1LdYmIiKiM0VuQZGJiAh8fH0RERMjSIyIi4OfnV+i6xsbGcHV1haGhIcLDw9G9e3cYGChXRRAExMbGwtnZ+YX2a2pqChsbG9mDiIiIyi8jfe580qRJGDx4MHx9fdGiRQv89NNPiI+Px5gxYwCIrTd3796V5kK6cuUKoqOj0axZM9y7dw8LFy7E+fPnsWrVKmmbM2bMQPPmzVGrVi2kp6fj+++/R2xsLJYuXVrs/RIRERHpNUjq168fUlNTMXPmTCQmJqJevXrYsWMH3NzcAACJiYmyuYtycnKwYMECXL58GcbGxmjfvj0iIyPh7u4u5bl//z5GjRqFpKQk2Nra4o033sDhw4fRtGnTYu+XiIiISK/zJJVlnCeJiIio7CkT8yQRERERlWYMkoiIiIgUMEgiIiIiUsAgiYiIiEgBgyQiIiIiBQySiIiIiBQwSCIiIiJSwCCJiIiISAGDJCIiIiIFDJKIiIiIFDBIIiIiIlLAIImIiIhIAYMkIiIiIgUMkoiIiIgUMEgiIiIiUsAgiYiIiEgBgyQiIiIiBQySiIiIiBQwSCIiIiJSwCCJiIiISAGDJCIiIiIFDJKIiIiIFDBIIiIiIlLAIImIiIhIAYMkIiIiIgUMkoiIiIgUMEgiIiIiUsAgiYiIiEgBgyQiIiIiBQySiIiIiBQwSCIiIiJSoHOQ5O7ujpkzZyI+Pv5llIeIiIioVNA5SJo8eTJ+++03VK9eHZ07d0Z4eDgyMzNfRtmIiIiI9EbnIGn8+PGIiYlBTEwMvL29MWHCBDg7O2PcuHE4ffr0yygjERER0SunEgRBeJENZGdnY9myZfj000+RnZ2NevXqYeLEiXjvvfegUqlKqpylTnp6OmxtbZGWlgYbGxt9F4eIiIiKQZfjt9Hz7iQ7Oxtbt27FihUrEBERgebNm2P48OFISEjA1KlTsXfvXvzyyy/Pu3kiIiIivdI5SDp9+jRWrFiB9evXw9DQEIMHD8aiRYvg6ekp5fH390ebNm1KtKBERFRycnJykJ2dre9iEJU4Y2NjGBoalsi2dA6SmjRpgs6dOyMkJAS9e/eGsbGxVh5vb2/079+/RApIREQlRxAEJCUl4f79+/ouCtFLU6FCBTg5Ob3wsB+dg6Tr16/Dzc2t0DyWlpZYsWLFcxeKiIheDnWAVLlyZVhYWJTrsaP0+hEEARkZGUhOTgYAODs7v9D2dA6SkpOTkZSUhGbNmsnST5w4AUNDQ/j6+r5QgYiI6OXIycmRAiR7e3t9F4fopTA3NwcgxiuVK1d+oa43nacA+OCDD3D79m2t9Lt37+KDDz7QuQDLli2Dh4cHzMzM4OPjgyNHjhSaf+nSpfDy8oK5uTnq1KmD1atXy5YvX74crVu3hp2dHezs7NCpUydER0fL8kyfPh0qlUr2cHJy0rnsRERliXoMkoWFhZ5LQvRyqT/jLzruTucg6eLFi2jcuLFW+htvvIGLFy/qtK0NGzYgODgYU6dOxZkzZ9C6dWsEBgYWOJt3SEgIpkyZgunTp+PChQuYMWMGPvjgA/z+++9SnoMHD2LAgAE4cOAAoqKiUK1aNfj7++Pu3buybdWtWxeJiYnS49y5czqVnYiorGIXG5V3JfUZ1zlIMjU1xT///KOVnpiYCCMj3XrvFi5ciOHDh2PEiBHw8vLC4sWLUbVqVYSEhCjmX7NmDUaPHo1+/fqhevXq6N+/P4YPH4558+ZJedatW4exY8eiUaNG8PT0xPLly5Gbm4t9+/bJtmVkZAQnJyfpUalSJZ3KTkREROWbzkFS586dMWXKFKSlpUlp9+/fx+eff47OnTsXeztZWVmIiYmBv7+/LN3f3x+RkZGK62RmZsLMzEyWZm5ujujo6AKb1DIyMpCdnY2KFSvK0uPi4uDi4gIPDw/0798f169fL3bZiYio7GvXrh2Cg4OLnf/mzZtQqVSIjY19aWWi0kXnIGnBggW4ffs23Nzc0L59e7Rv3x4eHh5ISkrCggULir2dlJQU5OTkwNHRUZbu6OiIpKQkxXUCAgLw888/IyYmBoIg4NSpUwgLC0N2djZSUlIU1/nss89QpUoVdOrUSUpr1qwZVq9ejd27d2P58uVISkqCn58fUlNTCyxvZmYm0tPTZQ8iInr58o8hzf8YOnToc213y5Yt+Prrr4udv2rVqkhMTES9evWea3/Pw9/fH4aGhjh+/Pgr2yfl0fnqtipVquCvv/7CunXrcPbsWZibm+O9997DgAEDFOdMKkr+fkNBEArsS5w2bRqSkpLQvHlzCIIAR0dHDB06FPPnz1ccvT5//nysX78eBw8elLVABQYGSv/Xr18fLVq0QI0aNbBq1SpMmjRJcd9z5szBjBkzdK4fERG9mMTEROn/DRs24Msvv8Tly5elNPXVTGrZ2dnFOh7l72EoiqGh4Su9yCc+Ph5RUVEYN24cQkND0bx581e2byXFfV3LE51bkgBxHqRRo0Zh6dKl+O677zBkyBCdXzgHBwcYGhpqtRolJydrtS6pmZubIywsDBkZGbh58ybi4+Ph7u4Oa2trODg4yPJ+9913mD17Nvbs2YMGDRoUWZ/69esjLi6uwDzqLkb1Q+kKPyIiKnma40dtbW2lK5KdnJzw5MkTVKhQARs3bkS7du1gZmaGtWvXIjU1FQMGDICrqyssLCxQv359rF+/Xrbd/N1t7u7umD17NoYNGwZra2tUq1YNP/30k7Q8f3fbwYMHoVKpsG/fPvj6+sLCwgJ+fn6yAA4AZs2ahcqVK8Pa2hojRozAZ599hkaNGhVZ7xUrVqB79+54//33sWHDBjx69Ei2/P79+xg1ahQcHR1hZmaGevXq4Y8//pCWHzt2DG3btoWFhQXs7OwQEBCAe/fuSXVdvHixbHuNGjXC9OnTpecqlQo//vgjevXqBUtLS8yaNQs5OTkYPnw4PDw8pKvM//e//2mVPSwsDHXr1oWpqSmcnZ0xbtw4AMCwYcPQvXt3Wd6nT5/CyckJYWFhRb4mr9pzBUmAeJXbrl27sH37dtmjuExMTODj44OIiAhZekREBPz8/Apd19jYGK6urjA0NER4eDi6d+8OA4O8qnz77bf4+uuvsWvXrmLN25SZmYlLly4VOumUqakpbGxsZA8iorJOEARkZD3Vy+MF768u8+mnn2LChAm4dOkSAgIC8OTJE/j4+OCPP/7A+fPnMWrUKAwePBgnTpwodDsLFiyAr68vzpw5g7Fjx+L999/H33//Xeg6U6dOxYIFC3Dq1CkYGRlh2LBh0rJ169bhm2++wbx58xATE4Nq1aoVeHGSJkEQsGLFCgwaNAienp6oXbs2Nm7cKC3Pzc1FYGAgIiMjsXbtWly8eBFz586VelViY2PRsWNH1K1bF1FRUTh69Ch69OiBnJycIvet6auvvkKvXr1w7tw5DBs2DLm5uXB1dcXGjRtx8eJFfPnll/j8889lZQsJCcEHH3yAUaNG4dy5c9i+fTtq1qwJABgxYgR27dolax3csWMHHj58iHfeeUensr0KzzXj9ptvvolz585BpVJJH3J1F5kub8CkSZMwePBg+Pr6okWLFvjpp58QHx+PMWPGABBbb+7evSvNhXTlyhVER0ejWbNmuHfvHhYuXIjz589j1apV0jbnz5+PadOm4ZdffoG7u7vUUmVlZQUrKysAwEcffYQePXqgWrVqSE5OxqxZs5Ceno6goCBdXw4iojLtcXYOvL/crZd9X5wZAAuT577PukxwcDDeeustWdpHH30k/T9+/Hjs2rULmzZt0poMWVPXrl0xduxYAGLgtWjRIhw8eFB2f9L8vvnmG7Rt2xaAOA62W7duePLkCczMzPDDDz9g+PDheO+99wAAX375Jfbs2YOHDx8WWp+9e/ciIyMDAQEBAIBBgwYhNDRU2s7evXsRHR2NS5cuoXbt2gCA6tWrS+vPnz8fvr6+WLZsmZRWt27dQvep5N1335UFfQBkQ088PDwQGRmJjRs3SkHOrFmzMHnyZEycOFHK16RJEwCAn58f6tSpgzVr1uCTTz4BILaYvf3229IxujTRuSVp4sSJ8PDwwD///AMLCwtcuHABhw8fhq+vLw4ePKjTtvr164fFixdj5syZaNSoEQ4fPowdO3ZItz1JTEyUzZmUk5ODBQsWoGHDhujcuTOePHmCyMhIuLu7S3mWLVuGrKws9O3bF87OztLju+++k/LcuXMHAwYMQJ06dfDWW2/BxMQEx48fL/J2K0REVDrl7zXIycnBN998gwYNGsDe3h5WVlbYs2dPgfPwqWkOz1B366lvcVGcddQ9Eup1Ll++jKZNm8ry53+uJDQ0FP369ZOm1hkwYABOnDghdeXFxsbC1dVVCpDyU7ckvSil3pgff/wRvr6+qFSpEqysrLB8+XLpdU1OTkZCQkKh+x4xYoR067Lk5GT8+eefWoFYaaFzCB8VFYX9+/ejUqVKMDAwgIGBAVq1aoU5c+ZgwoQJOHPmjE7bGzt2rBS157dy5UrZcy8vryK3f/PmzSL3GR4eXtziERGVa+bGhrg4M0Bv+y4plpaWsucLFizAokWLsHjxYtSvXx+WlpYIDg5GVlZWodvJP75WpVIhNze32Ouoe1U011G6QKkw//33H7Zt24bs7GxZ11xOTg7CwsIwb948rcHq+RW13MDAQKscSlPp5H9dN27ciA8//BALFixAixYtYG1tjW+//VbqxixqvwAwZMgQfPbZZ4iKikJUVBTc3d3RunXrItfTB52DpJycHKlJzMHBAQkJCahTpw7c3Ny0BqsREVHpplKpSqzLqzQ5cuQIevXqhUGDBgEQg5a4uDh4eXm90nLUqVMH0dHRGDx4sJR26tSpQtdZt24dXF1dsW3bNln6vn37MGfOHKmF7M6dO7hy5Ypia1KDBg2wb9++Aq/KrlSpkmxcUHp6Om7cuFFkfY4cOQI/Pz9Z48a1a9ek/62treHu7o59+/ahffv2ituwt7dH7969sWLFCkRFRUldiKWRzt+MevXq4a+//kL16tXRrFkzzJ8/HyYmJvjpp59k/aFERET6UrNmTWzevBmRkZGws7PDwoULkZSU9MqDpPHjx2PkyJHw9fWFn58fNmzYIB1DCxIaGoq+fftqzcfk5uaGTz/9FH/++Sd69eqFNm3aoE+fPli4cCFq1qyJv//+GyqVCl26dMGUKVNQv359jB07FmPGjIGJiQkOHDiAt99+Gw4ODujQoQNWrlyJHj16wM7ODtOmTSvWjWBr1qwpzTPo4eGBNWvW4OTJk/Dw8JDyTJ8+HWPGjEHlypURGBiIBw8e4NixYxg/fryUZ8SIEejevTtycnJK9XhgncckffHFF1Iz4qxZs3Dr1i20bt0aO3bswPfff1/iBSQiItLVtGnT0LhxYwQEBKBdu3ZwcnJC7969X3k5Bg4ciClTpuCjjz5C48aNcePGDQwdOlTr7hFqMTExOHv2LPr06aO1zNraGv7+/ggNDQUAbN68GU2aNMGAAQPg7e2NTz75RLp4qnbt2tizZw/Onj2Lpk2bokWLFvjtt9+kMU5TpkxBmzZt0L17d3Tt2hW9e/dGjRo1iqzPmDFj8NZbb6Ffv35o1qwZUlNTtYbMBAUFYfHixVi2bBnq1q2L7t27a02x06lTJzg7OyMgIAAuLi5Fv5B6ohJK4BrM//77D3Z2dq/VTRPT09Nha2uLtLQ0TgdARGXCkydPcOPGDXh4eBR4kKaXr3PnznBycsKaNWv0XRS9ycjIgIuLC8LCwrSuSiwJhX3WdTl+69Td9vTpU5iZmSE2NlbWDKjrrKVERESvg4yMDPz4448ICAiAoaEh1q9fj71792rNEfi6yM3NlW5jZmtri549e+q7SIXSKUgyMjKCm5ubzpNRERERvY5UKhV27NiBWbNmITMzE3Xq1MHmzZtl9xN9ncTHx8PDwwOurq5YuXKl1P1XWulcui+++AJTpkzB2rVr2YJERERUCHNzc+zdu1ffxSg13N3dS3Sm9ZdN5yDp+++/x9WrV+Hi4gI3NzetORROnz5dYoUjIiIi0hedgyR9XB1ARERE9KrpHCR99dVXL6McRERERKWKzvMkEREREb0OdG5JMjAwKHQ+JF75RkREROWBzkHS1q1bZc+zs7Nx5swZrFq1qsB7xBARERGVNToHSb169dJK69u3L+rWrYsNGzZg+PDhJVIwIiKiktSuXTs0atQIixcvBiBejh4cHIzg4OAC11GpVNi6desLX7RUUtuhV6vExiQ1a9aMc0EQEVGJ69GjR4GTL0ZFRUGlUj3X9DMnT57EqFGjXrR4MtOnT0ejRo200hMTExEYGFii+yrI48ePYWdnh4oVK+Lx48evZJ/lVYkESY8fP8YPP/wAV1fXktgcERGRZPjw4di/fz9u3bqltSwsLAyNGjVC48aNdd5upUqVYGFhURJFLJKTkxNMTU1fyb42b96MevXqwdvbG1u2bHkl+yyIIAh4+vSpXsvwInQOktTRqfphZ2cHa2trhIWF4dtvv30ZZSQiotdY9+7dUblyZaxcuVKWnpGRIQ3zSE1NxYABA+Dq6goLCwvUr18f69evL3S77u7uUtcbAMTFxaFNmzYwMzODt7e34v3VPv30U9SuXRsWFhaoXr06pk2bhuzsbADAypUrMWPGDJw9exYqlQoqlUoqs0qlwrZt26TtnDt3Dh06dIC5uTns7e0xatQoPHz4UFo+dOhQ9O7dG9999x2cnZ1hb2+PDz74QNpXYUJDQzFo0CAMGjQIoaGhWssvXLiAbt26wcbGBtbW1mjdujWuXbsmLQ8LC0PdunVhamoKZ2dnjBs3DgBw8+ZNqFQqxMbGSnnv378PlUqFgwcPAgAOHjwIlUqF3bt3w9fXF6ampjhy5AiuXbuGXr16wdHREVZWVmjSpIlW71NmZiY++eQTVK1aFaampqhVqxZCQ0MhCAJq1qyJ7777Tpb//PnzMDAwkJW9pOk8JmnRokWyq9sMDAxQqVIlNGvWDHZ2diVaOCIieskEAcjO0M++jS2AQq6WVjMyMsKQIUOwcuVKfPnll9IxaNOmTcjKysLAgQORkZEBHx8ffPrpp7CxscGff/6JwYMHo3r16mjWrFmR+8jNzcVbb70FBwcHHD9+HOnp6YpjlaytrbFy5Uq4uLjg3LlzGDlyJKytrfHJJ5+gX79+OH/+PHbt2iUFALa2tlrbyMjIQJcuXdC8eXOcPHkSycnJGDFiBMaNGycLBA8cOABnZ2ccOHAAV69eRb9+/dCoUSOMHDmywHpcu3YNUVFR2LJlCwRBQHBwMK5fv47q1asDAO7evYs2bdqgXbt22L9/P2xsbHDs2DGptSckJASTJk3C3LlzERgYiLS0NBw7dqzI1y+/Tz75BN999x2qV6+OChUq4M6dO+jatStmzZoFMzMzrFq1Cj169MDly5dRrVo1AMCQIUMQFRWF77//Hg0bNsSNGzeQkpIClUqFYcOGYcWKFfjoo4+kfYSFhaF169aoUaOGzuUrLp2DpKFDh76EYhARkV5kZwCzXfSz788TABPLovMBGDZsGL799lscPHgQ7du3ByAeJN966y3Y2dnBzs5OdgAdP348du3ahU2bNhUrSNq7dy8uXbqEmzdvSkNHZs+erTWO6IsvvpD+d3d3x+TJk7FhwwZ88sknMDc3h5WVFYyMjODk5FTgvtatW4fHjx9j9erV0q29lixZgh49emDevHlwdHQEIPbcLFmyBIaGhvD09ES3bt2wb9++QoOksLAwBAYGSo0WXbp0QVhYGGbNmgUAWLp0KWxtbREeHg5jY2MAQO3ataX1Z82ahcmTJ2PixIlSWpMmTYp8/fKbOXMmOnfuLD23t7dHw4YNZfvZunUrtm/fjnHjxuHKlSvYuHEjIiIipPFn6sAOAN577z18+eWXiI6ORtOmTZGdnY21a9e+9B4snbvbVqxYgU2bNmmlb9q0CatWrSqRQhEREWny9PSEn58fwsLCAIgtJkeOHMGwYcMAiHP0ffPNN2jQoAHs7e1hZWWFPXv2ID4+vljbv3TpEqpVqyYbW9uiRQutfL/++itatWoFJycnWFlZYdq0acXeh+a+GjZsKLv3acuWLZGbm4vLly9LaXXr1oWhoaH03NnZGcnJyQVuNycnB6tWrcKgQYOktEGDBmHVqlXSHIaxsbFo3bq1FCBpSk5ORkJCAjp27KhTfZT4+vrKnj969AiffPIJvL29UaFCBVhZWeHvv/+WXrvY2FgYGhqibdu2ittzdnZGt27dpPf/jz/+wJMnT/D222+/cFkLo3NL0ty5c/Hjjz9qpVeuXBmjRo1CUFBQiRSMiIheAWMLsUVHX/vWwfDhwzFu3DgsXboUK1asgJubm3RAX7BgARYtWoTFixejfv36sLS0RHBwMLKysoq1baU70+efOPn48ePo378/ZsyYgYCAAKlFZsGCBTrVQxCEAidl1kzPH8ioVCrk5uYWuN3du3fj7t276Nevnyw9JycHe/bsQWBgIMzNzQtcv7BlgDi8Rl1+tYLGSGkGgADw8ccfY/fu3fjuu+9Qs2ZNmJubo2/fvtL7U9S+AWDEiBEYPHgwFi1ahBUrVqBfv34vfeC9zi1Jt27dgoeHh1a6m5ubztE0ERHpmUoldnnp41GM8Uia3nnnHRgaGuKXX37BqlWr8N5770lBxZEjR9CrVy8MGjQIDRs2RPXq1REXF1fsbXt7eyM+Ph4JCXkBY1RUlCzPsWPH4ObmhqlTp8LX1xe1atXSuuLOxMSkyDtPeHt7IzY2Fo8ePZJt28DAQNb1pavQ0FD0798fsbGxssfAgQOlAdwNGjTAkSNHFIMba2truLu7Y9++fYrbr1SpEgBxOgM1zUHchTly5AiGDh2KN998E/Xr14eTkxNu3rwpLa9fvz5yc3Nx6NChArfRtWtXWFpaIiQkBDt37pRaEV8mnYOkypUr46+//tJKP3v2LOzt7UukUERERPlZWVmhX79++Pzzz5GQkCAbI1uzZk1EREQgMjISly5dwujRo5GUlFTsbXfq1Al16tTBkCFDcPbsWRw5cgRTp06V5alZsybi4+MRHh6Oa9eu4fvvv9e6C4W7uztu3LiB2NhYpKSkIDMzU2tfAwcOhJmZGYKCgnD+/HkcOHAA48ePx+DBg6XxSLr6999/8fvvvyMoKAj16tWTPYKCgrB9+3b8+++/GDduHNLT09G/f3+cOnUKcXFxWLNmjdTNN336dCxYsADff/894uLicPr0afzwww8AxNae5s2bY+7cubh48SIOHz4sG6NVmJo1a2LLli2IjY3F2bNn8e6778paxdzd3REUFIRhw4Zh27ZtuHHjBg4ePIiNGzdKeQwNDTF06FBMmTIFNWvWVOwOLWk6B0n9+/fHhAkTcODAAeTk5CAnJwf79+/HxIkT0b9//5dRRiIiIgBil9u9e/fQqVMn6aooAJg2bRoaN26MgIAAtGvXDk5OTjrNbm1gYICtW7ciMzMTTZs2xYgRI/DNN9/I8vTq1Qsffvghxo0bh0aNGiEyMhLTpk2T5enTpw+6dOmC9u3bo1KlSorTEFhYWGD37t3477//0KRJE/Tt2xcdO3bEkiVLdHsxNKgHgSuNJ2rfvj2sra2xZs0a2NvbY//+/Xj48CHatm0LHx8fLF++XOraCwoKwuLFi7Fs2TLUrVsX3bt3l7XIhYWFITs7G76+vpg4caI0ILwoixYtgp2dHfz8/NCjRw8EBARozW0VEhKCvn37YuzYsfD09MTIkSNlrW2A+P5nZWW9klYkAFAJSh2xhcjKysLgwYOxadMmGBmJQ5pyc3MxZMgQ/PjjjzAxMXkpBS1t0tPTYWtri7S0NNjY2Oi7OERERXry5Alu3LgBDw8PmJmZ6bs4RDo7duwY2rVrhzt37hTa6lbYZ12X47fOA7dNTEywYcMGzJo1C7GxsTA3N0f9+vXh5uam66aIiIiIipSZmYnbt29j2rRpeOedd567W1JXOgdJarVq1UKtWrVKsixEREREWtavX4/hw4ejUaNGWLNmzSvbr85jkvr27Yu5c+dqpX/77bcvfb4CIiIiev0MHToUOTk5iImJQZUqVV7ZfnUOkg4dOoRu3bpppXfp0gWHDx8ukUIRERER6ZvOQdLDhw8VB2cbGxsjPT29RApFREQvj47X6xCVOSX1Gdc5SKpXrx42bNiglR4eHg5vb+8SKRQREZU89WXeGRl6uqEt0Sui/owr3X5FFzoP3J42bRr69OmDa9euoUOHDgCAffv24ZdffsGvv/76QoUhIqKXx9DQEBUqVJDu/2VhYVHg7TGIyiJBEJCRkYHk5GRUqFBBdu+756FzkNSzZ09s27YNs2fPxq+//gpzc3M0bNgQ+/fv53xBRESlnPru9IXdKJWorKtQoYL0WX8ROk8mmd/9+/exbt06hIaG4uzZs0Xes6a84GSSRFSW5eTkFHhzUqKyzNjYuNAWpJc6maTa/v37ERYWhi1btsDNzQ19+vSRbqBHRESlm6Gh4Qt3RRCVdzoFSXfu3MHKlSsRFhaGR48e4Z133kF2djY2b97MQdtERERUrhT76rauXbvC29sbFy9exA8//ICEhATpzsBERERE5U2xW5L27NmDCRMm4P333+ftSIiIiKjcK3ZL0pEjR/DgwQP4+vqiWbNmWLJkCf7999+XWTYiIiIivSl2kNSiRQssX74ciYmJGD16NMLDw1GlShXk5uYiIiICDx48eJnlJCIiInqldJ5x28LCAsOGDcPRo0dx7tw5TJ48GXPnzkXlypXRs2dPnQuwbNkyeHh4wMzMDD4+Pjhy5Eih+ZcuXQovLy+Ym5ujTp06WL16tVYe9UByU1NTeHt7Y+vWrS+8XyIiInrNCCXg6dOnwtatW4UePXrotF54eLhgbGwsLF++XLh48aIwceJEwdLSUrh165Zi/mXLlgnW1tZCeHi4cO3aNWH9+vWClZWVsH37dilPZGSkYGhoKMyePVu4dOmSMHv2bMHIyEg4fvz4c+9XSVpamgBASEtL06nOREREpD+6HL9feDLJF9GsWTM0btwYISEhUpqXlxd69+6NOXPmaOX38/NDy5Yt8e2330ppwcHBOHXqFI4ePQoA6NevH9LT07Fz504pT5cuXWBnZ4f169c/136VcDJJIiKiskeX47fO3W0lJSsrCzExMfD395el+/v7IzIyUnGdzMxMmJmZydLMzc0RHR0tzRwbFRWltc2AgABpm8+zXyIiInr96C1ISklJQU5ODhwdHWXpjo6OSEpKUlwnICAAP//8M2JiYiAIAk6dOoWwsDBkZ2cjJSUFAJCUlFToNp9nv4AYoKWnp8seREREVH7pLUhSy38HakEQCrwr9bRp0xAYGIjmzZvD2NgYvXr1wtChQwFANr1+cbapy34BYM6cObC1tZUeVatWLbJuREREVHbpLUhycHCAoaGhVutNcnKyViuPmrm5OcLCwpCRkYGbN28iPj4e7u7usLa2hoODAwDxDteFbfN59gsAU6ZMQVpamvS4ffu2znUmIiKiskNvQZKJiQl8fHwQEREhS4+IiICfn1+h6xobG8PV1RWGhoYIDw9H9+7dYWAgVqVFixZa29yzZ4+0zefdr6mpKWxsbGQPIiIiKr90usFtSZs0aRIGDx4MX19ftGjRAj/99BPi4+MxZswYAGLrzd27d6W5kK5cuYLo6Gg0a9YM9+7dw8KFC3H+/HmsWrVK2ubEiRPRpk0bzJs3D7169cJvv/2GvXv3Sle/FWe/RERERHoNkvr164fU1FTMnDkTiYmJqFevHnbs2AE3NzcAQGJiIuLj46X8OTk5WLBgAS5fvgxjY2O0b98ekZGRcHd3l/L4+fkhPDwcX3zxBaZNm4YaNWpgw4YNaNasWbH3S0RERKTXeZLKMs6TREREVPaUiXmSiIiIiEozBklEREREChgkERERESlgkERERESkgEESERERkQIGSUREREQKGCQRERERKWCQRERERKSAQRIRERGRAgZJRERERAoYJBEREREpYJBEREREpIBBEhEREZECBklEREREChgkERERESlgkERERESkgEESERERkQIGSUREREQKGCQRERERKWCQRERERKSAQRIRERGRAgZJRERERAoYJBEREREpYJBEREREpIBBEhEREZECBklEREREChgkERERESlgkERERESkgEESERERkQIGSUREREQKGCQRERERKWCQRERERKSAQRIRERGRAgZJRERERAoYJBEREREpYJBEREREpIBBEhEREZECBklEREREChgkERERESlgkERERESkQO9B0rJly+Dh4QEzMzP4+PjgyJEjheZft24dGjZsCAsLCzg7O+O9995DamqqtLxdu3ZQqVRaj27dukl5pk+frrXcycnppdWRiIiIyh69BkkbNmxAcHAwpk6dijNnzqB169YIDAxEfHy8Yv6jR49iyJAhGD58OC5cuIBNmzbh5MmTGDFihJRny5YtSExMlB7nz5+HoaEh3n77bdm26tatK8t37ty5l1pXIiIiKlv0GiQtXLgQw4cPx4gRI+Dl5YXFixejatWqCAkJUcx//PhxuLu7Y8KECfDw8ECrVq0wevRonDp1SspTsWJFODk5SY+IiAhYWFhoBUlGRkayfJUqVXqpdSUiIqKyRW9BUlZWFmJiYuDv7y9L9/f3R2RkpOI6fn5+uHPnDnbs2AFBEPDPP//g119/lXWl5RcaGor+/fvD0tJSlh4XFwcXFxd4eHigf//+uH79eqHlzczMRHp6uuxBRERE5ZfegqSUlBTk5OTA0dFRlu7o6IikpCTFdfz8/LBu3Tr069cPJiYmcHJyQoUKFfDDDz8o5o+Ojsb58+dl3XEA0KxZM6xevRq7d+/G8uXLkZSUBD8/P9nYpvzmzJkDW1tb6VG1alUda0xERERlid4HbqtUKtlzQRC00tQuXryICRMm4Msvv0RMTAx27dqFGzduYMyYMYr5Q0NDUa9ePTRt2lSWHhgYiD59+qB+/fro1KkT/vzzTwDAqlWrCiznlClTkJaWJj1u376tSzWJiIiojDHS144dHBxgaGio1WqUnJys1bqkNmfOHLRs2RIff/wxAKBBgwawtLRE69atMWvWLDg7O0t5MzIyEB4ejpkzZxZZFktLS9SvXx9xcXEF5jE1NYWpqWlxqkZERETlgN5akkxMTODj44OIiAhZekREBPz8/BTXycjIgIGBvMiGhoYAxBYoTRs3bkRmZiYGDRpUZFkyMzNx6dIlWZBFRERErze9drdNmjQJP//8M8LCwnDp0iV8+OGHiI+Pl7rPpkyZgiFDhkj5e/TogS1btiAkJATXr1/HsWPHMGHCBDRt2hQuLi6ybYeGhqJ3796wt7fX2u9HH32EQ4cO4caNGzhx4gT69u2L9PR0BAUFvdwKExERUZmht+42AOjXrx9SU1Mxc+ZMJCYmol69etixYwfc3NwAAImJibI5k4YOHYoHDx5gyZIlmDx5MipUqIAOHTpg3rx5su1euXIFR48exZ49exT3e+fOHQwYMAApKSmoVKkSmjdvjuPHj0v7JSIiIlIJ+fupqFjS09Nha2uLtLQ02NjY6Ls4REREVAy6HL/1fnUbERERUWnEIImIiIhIAYMkIiIiIgUMkoiIiIgUMEgiIiIiUsAgiYiIiEgBgyQiIiIiBQySiIiIiBQwSCIiIiJSwCCJiIiISAGDJCIiIiIFDJKIiIiIFDBIIiIiIlLAIImIiIhIAYMkIiIiIgUMkoiIiIgUMEgiIiIiUsAgiYiIiEgBgyQiIiIiBQySiIiIiBQwSCIiIiJSwCCJiIiISAGDJCIiIiIFDJKIiIiIFDBIIiIiIlLAIImIiIhIAYMkIiIiIgUMkoiIiIgUMEgiIiIiUsAgiYiIiEgBgyQiIiIiBQySiIiIiBQwSCIiIiJSwCCJiIiISAGDJCIiIiIFDJKIiIiIFDBIIiIiIlLAIImIiIhIAYMkIiIiIgUMkoiIiIgU6D1IWrZsGTw8PGBmZgYfHx8cOXKk0Pzr1q1Dw4YNYWFhAWdnZ7z33ntITU2Vlq9cuRIqlUrr8eTJkxfaLxEREb1e9BokbdiwAcHBwZg6dSrOnDmD1q1bIzAwEPHx8Yr5jx49iiFDhmD48OG4cOECNm3ahJMnT2LEiBGyfDY2NkhMTJQ9zMzMnnu/RERE9PrRa5C0cOFCDB8+HCNGjICXlxcWL16MqlWrIiQkRDH/8ePH4e7ujgkTJsDDwwOtWrXC6NGjcerUKVk+lUoFJycn2eNF9ktERESvH70FSVlZWYiJiYG/v78s3d/fH5GRkYrr+Pn54c6dO9ixYwcEQcA///yDX3/9Fd26dZPle/jwIdzc3ODq6oru3bvjzJkzL7RfAMjMzER6errsUe5ELQViVum7FHluHgV2fQ5kPyk6LwAkxAKbRwIbg8THb+OAh8kF579/G9j5KZCeWCLFLVG5OUDEV3l12RgEXNiq71K9Ov9cAHZPBZ48x/fsQRKwawqQdrfky1UW/LUROPF/z7du3F7g0Hzx80dEMNLXjlNSUpCTkwNHR0dZuqOjI5KSkhTX8fPzw7p169CvXz88efIET58+Rc+ePfHDDz9IeTw9PbFy5UrUr18f6enp+N///oeWLVvi7NmzqFWr1nPtFwDmzJmDGTNmvECNS7n0BGD354DKEKj/NmBioe8SAXumAQmnAVdfoN5bxcj/BXAz39gyC3ugcwHv276ZwLmNQNYjoNeSFy9vSYrbAxxbLE+7uheo0xUwMtVLkV6pHZ8At44CJlZA+ym6rbvvayB2LSDkAoHzXk75SqtHqcDW0WLd3fwAp/rFXzfnKbBlBPD4HlDZG/Dq/vLKSVRG6H3gtkqlkj0XBEErTe3ixYuYMGECvvzyS8TExGDXrl24ceMGxowZI+Vp3rw5Bg0ahIYNG6J169bYuHEjateuLQukdN0vAEyZMgVpaWnS4/bt27pWtXRLuSL+FXKA/67rtywAIAhASpz4v/pvYR7fB249awnsNAPwHS7+f2W3cv6cp8DVCPH/uD1Abu4LFbfEXdkl/q3REej6HWBZCch6KLaulXeP7wHxUeL/6tehuHJzgbhn7/m/l0u2XGXB1QgxQAJ0f+3unBRf++dZl6ic0luQ5ODgAENDQ63Wm+TkZK1WHrU5c+agZcuW+Pjjj9GgQQMEBARg2bJlCAsLQ2KicpeJgYEBmjRpgri4uOfeLwCYmprCxsZG9ihXUq8q/68vD5OBrAfi/8Upz7V9YoBXyRNoFQx0+EJsFfv3EnDvpnZ+zQPCw3+AxNgSKngJEIS84K7FWKDpSKBOoPi8oKCvPLn67L0ExPdFl+7QhDPAo3/F/1OvlXjRSj3N4EbXz4rmuqXxxIFID/QWJJmYmMDHxwcRERGy9IiICPj5+Smuk5GRAQMDeZENDQ0BiC1BSgRBQGxsLJydnZ97v68FzQNKaQiSdA3a1AeE2gHiX4uKQLXmz5btUcif70y5NAUfSX8BDxIBY0vArZWYVruL+PfKLjGIKs/yvxdxCu9fgetqvK9pt4HsxyVTprIgJ1sMMNXunAIe/lv89TVf99J24kCkJ3rtbps0aRJ+/vlnhIWF4dKlS/jwww8RHx8vdZ9NmTIFQ4YMkfL36NEDW7ZsQUhICK5fv45jx45hwoQJaNq0KVxcXAAAM2bMwO7du3H9+nXExsZi+PDhiI2NlXXJFbXf15IsKCkFZ+D5y1NYYJCbk3cgVQcTQF7ApNR1oD4g1OhQcB59kcrWHjB+NnWFR1vA0BS4f6t8dyNpdoNK740OAazsfRSA/26UWNFKvfgoIDMdsHAAHOsDEPJey6Lcuym2uqoMAY82YlppOnEg0hO9Bkn9+vXD4sWLMXPmTDRq1AiHDx/Gjh074ObmBgBITEyUzV00dOhQLFy4EEuWLEG9evXw9ttvo06dOtiyZYuU5/79+xg1ahS8vLzg7++Pu3fv4vDhw2jatGmx9/taKm3dbZplyEwDHqUUnFfddWZWAXDNe5+lgOnmESDzYV665gGhy7OBvbp267xM6gO9OsgDAFMrwKO1fHl5pPledpgmpl0/ULwrHNMTxFY4qAA7DzGtNHyWXxXN1lSpe7aYnxV1a2u15kCD/rqtS1SO6X3g9tixY3Hz5k1kZmYiJiYGbdq0kZatXLkSBw8elOUfP348Lly4gIyMDCQkJGDt2rWoUqWKtHzRokW4desWMjMzkZycjN27d6NFixY67fe18zQLuHcr73lpOLDkb80qrEzqH/NanQFDjQs2HWoDdu5AThZw/aBGfvUBoQVQqTZQxUd8rku3zsvyMBm4GyP+X0s+TUVel1s5PsOX3kt/wOUNwNoFyM4o3oB19evi2gSo+ixYLg2f5VdFM7hWf1au7he/37qsW6szAFXpOnEg0hO9B0lUCty/JQ6UNXrWtfP4PyDjP/2WSX1wMzKXP1cinUF3kaerVPKxPFL+fC01pSn4UAdqLm8A1vJJUKWg6fZx/b8/L4tma4hKVXiXaWHr2tcU/y8NXcevQspV8TtiYAxUby9+fiwriRc/xBc8/xsAsZVVPXVG7S6AVeXSdeJApEcMkigvAHGoDdg8a5XT58ElV2Maghrtn5WngCDp3i0g+aLYdaYew6JJfZBVX62T/4Cgmae43TovkxTAddFeZucmzl8j5MoH6JYXmt2gNTuKaZoBbGHj0rIf57UW1u4C2NcQ/39dWpLU0x64twTMbAADA6CWOsAsIvi/flBsbbVzF38DgNJ14kCkR3qbTJJekr93ABU9gMpexV9HfSCxrwmYVwDS74ppVZuUbNn+uSi2WqnHS6ilXAWSLwDevcTn9+OB3GxxoLJHW+DyjoIPdnEaYyksKmovd2spTkj48B9xssnM9GcHBA/AoZaYx6kBYO0sXlG267O8QFEfrh0Q/2qOR9JUO0AMCk+EKE9t8CKc6gN18gVnd07llell++ec+LdaC8DcTvzfo43YwpkWD0R8CZgWMPVG+h3g6WPAxhVwrJs3hYDm5+ZppjgbtVf3vO0DYmB8etXzze79vGp1Elt7iuPKHiDxbOF5zm8W/+a/cCF2LXBhG2Cu8N1Qu7Yvb131XHF1ugAHZuWdOKgvIChM2l2xW7T+22KQpotHKUDsL+J7BIiT2b4xCDCzVc6f+RA4syZvrKGRiTiWylpjGpenWeL7+vi+9voGhkDdN8XfSjVBAC5sAVway9MB4NLvgEMdsXte05U9gK0r4OhdcN3+3iHOIK+kWvO8sYZqt0+Kv1HuLQvepq7+uQhc/hNQn2fYOAONBua934VJTwRuHALqvyN/X9MTgb82iFdVAoCpNdB4MGBimZcn4z8gdl3eyaexOfDGQPn3T1PWI+D0GiDzQV5aZU/Aq0exq1rSGCSVJ7ejgfABgG1VIPhc8b4AQN5kjeog6cZhILUYEzjqIjcX+OUd8bLs4RF5Y0YAYMNA4N+/gUFbxBYEKWirkRfIFBQkXd4p/i0oqDAyFVuYLm0Hji/NS68TmPf6qLvlYlaID32zdgacGiovqx0IHF0kjltSj10qMSpgwpm8A0RONrCub958Uq+KZqBmYgFUbye2sEV+X7x1VSqg4rOWpIwUsfzmdsDRxcDB2cDtE/IZ1k/+DOyZWpI1KNrJn4FJl4oOJu7fBtb3y5sgsiia34Ma7cUTjQcJYsBT5Loar7tjPfFkIf2u2PJaq3PR6/82VmyVEnKARu8Wr7xq+2YAp1fL0x7+A3SeqZw/8nvgUL7Z1JPOA32W5z2PWQns/LjgfV7bDwz9I+/5338Cvw4Tg6RRGicG1w8BGwYB9rWAcSfzfjfuxAC/vC3+bo4v4LuYeg0Ifxd50Uk+RubApzfzgtCnmcCaN4GnT8TfcBvngstfXIIAbBys/Rtq4aB9UqTk9wniyejTJ4DP0Lz0XZ8BF7fJ82Y9ANpovOb7ZwGnQuV50u8CXeYo7+v4MnEdTfX6MkiiEnLpd/Fv2m3xzNOlUfHWU3etqYMkoOS7KZLOiuUCgL//yAuSUq6KAZI6PX+QpB5b8t91sRvOwDBvm0pdZ0o6zxADj6fPzmZMrMQJJzW1/VQ8y8l69NxVLBEqFVCvT8EHz6pNgYA5ea9ZSblxSGyZurIbaP5sKoz4qGdXmtkC3r1Ldn8FMbcDfN6Tp/nPAipUy2tlKIiJJdByovi/qVVe62DqNfHWNn8/+35c3iH/LP39p/jXo63Y5fSynd8MPEzKu+VOYa7sEgOkCtXEsUaFcfUFKlbPe25qDfQNBeKKMQ1ARQ8xGFVTjwc7FSaWoagg6fE94Maz7+KlP3QLknJzxdYWAPDqKbaiXNklphUUJKnz1+wkti5e2CJ2OeZkA4bGz/I8C4DcW8tfl9wcsYXt1jGxpUPdAq3On3BabBWzrSJPT40T70xQqU6+9Kvi74ZmC4ra5Z0ABLHl2iPfxUF/bRRbP+/dyGv5/+9G3iS6cbvlQcnzSonLG6/W6F3xCtCEM2LLUlFBUuaDvJbkS3/kledppnibJEAMYh7fE1sk/96RFyQJgvhdAwDP7s+e/yl+3wJmK5/Eq9/XGh3Ek30gb3ycnjBIKk80xw9c2a1DkJSvuw0o+TFJ+cum/vHLP0OwIMjLY+sqng3nZIpBluZBTGkshZKK1YGu8wsvn41zwWc3pYlKJc7CXdIifxC7I6/syguS1O+ZZ3egZzFacV4Wh1pA1291X8++5rMg6aoYMCU9687LSBVb4ao2FQ+St4+L6T1/EMd9vWyZ6eLNiq/sKkaQ9Ow98B2uHdgXh1eP5z8Lr93lWZC0W7w1TmEt05qzpOvSRQeIQUlGihjs9AkVT2bme4hBSeq1vPFlaml3nnXNqoA3f3rW+n1IfF9vnwDcW4ldp7eOifl7/E97GwmnxW7rq/uABm/L51oDxADFd9iz2e/zXfShDpI0f9P+u658nzz1us1GA83fly9LOieWI/VqXpCkeXJ6pYSCJHUZPFqL3+Nr+8XWqivPxmkW1pp57YA49AEQexjUweCtY+JtkqwcgbeWi7PcL6gt1ufBP2K3pzQproX4vgo5wDyPvLneKnvK9/XgH3F9AOgdon3hip5w4HZ58d91IEVjksHiznGS+UA8qwUA++ryq4JK8rYEmuX59++8Sf4009PvAv+clwdJBoZ5Z4H5W7c0BzkXt2uRlElzSh3NGw+gNF9TWaI5eDtut3yZum5X94ktNZW9X02ABChfcakk65F4YNJc51XyaCN2B6XdFgOKwmgGDMWdskFaV32fwg7i2CIzG3EsYf7t5t9X1aaApb34G6G+8lO9rWv7gdyn4m9I/gAJ0L5q8m6MGGTl38e/f4tjJPOn348Xx1GqKbW8P76fdw9Cpe+Q9FtbwBx11w+WzIzx+a/+lcZpJokt/MVZFxBPVK8fkqfX8heDLGtHsZsSyAs21XmqP5sU18RSY6JShc9+YVf26hGDpPJCPfdP5WcDCNURfVHULUYWDmJXR4VqgIGR2Az8IKFkyvYgSWze1Sxf3B75j0jluuLfK7vk3X+AxsFOo3UrN1djlu0yehAvTexrisFobrZ49pj/kvKySPMgpP7Blj5nz57rIxCs+WweoqRzYrdOQa4fEg9MFdzyWi9eJWNzoHpb8f/CAjrNWdI1v8fFpXRFZ2GBZP5bEGn+L72vBUwLkn/7VyPE8qv3oy7/9YNAVoZ2evyz6TfyB29KQZI6UHOoLe/uUysqSNI12FSiebNodSBpZJp31XBhVy9q3ixa830VBI2xoIW8Z0rfrfzvk6bCruzVIwZJ5YX6A9ZoYN5VM8WZ40Sz1QYQ+/PVXVolNS5JOkNonDdW4cou+Y9I05Fi+oXf8sYuSUGSwo9JYqw4sNPEKu+sk56fbE6p3dqXlJdF6s9N0vm8M+DAuYDKQGyx/O9G3sH9Vf4wW9rnjcnL38KlqTS0lBZ2UFNTz5Jubge0n5KXvzj3GEy7+6wbVCUf96Te761j8qsOszLErjVA/p7V6CCe3KVcEQP8ok6gXJuIV/w9SRO76NT1azlBHAvz9InYiqdObzIMqOQldhld25+XbllJ/Ks0PEEpmNOkdPKn/l+93Red9VzdDVrJU37FXnFaM9U3iza1ATo+m/3+ym6xq+z+LcDQRD6OTV3PawfECw6UJsVV58k/19vTzKKv7NUTBknlQeaDvDOO2l2K35wPaLfaaP5fUkGS5lmdZreOdNlyQN4XQ30ZuJktYGFfcHk0729mZFoy5XzdSXNK7VY+UyxrpM9NXN70AO6tgarNxPT9X4sHSXM78aD5KhUVfAhC0QfZV0E919LtaOBRqnIe9e9Mzc5AjY55UzYkXyp6++og0bUJYOmQl25fQ7yaLPepGJSo3TgsBjC2VfNapQHx98Lt2Q3KD87OG+NUTftuCwDkXXQnfxaDZpWBWAf16332FzGAUr8O6vTzW/K6QZs8O7nL/1tZ0P0kNRXWkqTebnGDzYIU9BlS1z3hjNjSr7iuRjdo9fbiDbcfJgGHn43vdG8tXiCh5txQHPuX/QjY+9WztEbyK/QqVBNbpfLP9XbzqLielVPBV/bqCYOk8kA9uK5iDcChpjyiL+qKIM0rydRKcrbi7CfyMwR1t05OVt7VIbW7ADYu4nxFmmVQnz0rBkmls2m2TKvmB5hYi2eP0lWDpeusTicV3MSJKdXyz+KtDtJr+cuvmnwV1J9bdbdOfolnxQOSsaU4EFlfbKs8G5BcyM1yNQ/EJhaFjzspbN38lAJJzS6c/K1r6tdU/b7W7Jh3pZsS9fYvPLv3p+uzMU7q7Vz8TTyYO9YDKlTNS7/857Nu0GqAZzcxLX+QdOeUeOcCM9u8oDw/9W/uo3/FoQdP0oBHyWKa73vFHw9WEM1u0Py/k8WZVV3zN9bYLK+LTmlOLkB8P9TBV0F5AOVZ9KXPgb/uc2y9ZKWrNPR88ve/OzUUI/LsR0X3aefvbgNKdrbiW8/OEKydxTMNzW4dQP4jopmu1LJ1/7YYdKUnit1tgPb9zej5GZkANTVmLS9oLEVZYWQiH4wtzbCe74dbH4FgZe+8bh11QKqpNLWUFtYyrThLejFn+s7KkM+SXtB+4/aILTOy1rVC8hf0PD91F52U/1m53VuLV2TlT3dtIp8EUXNm98f35C1tV561xNbsVHCgZmot/k4DwH/X8k5KrRzFIKY448EKU9CNvzXLDyi/T5o3i1Z3g+b/ntRW+O0tzncr/3gwzSsIS+FJL6cAKG3SE4qeXTe/uHxnYwYG4gf49GpxQrWcQm5wqRgkPfv/nwt53S7PK/YX8W8t/7wzv9oB4qRhgPxHpHaXvKZczfJYOgCmtkBmmjh7671nV8ZV8RF/TKjk1O4inkEDZbsVSc2+pnjlp5F53szGlTzFVoD78c9uZ9Px1ZdL3aJ18mfxe5p/skj1JH2l4aBRuwtw+Fuxe+TvHfIWHHWQozlLeq0AAJOBO9HibN8FBXn/XBCDRPUs6flVay5+7zNSxNfJ0Fi8mMTYQgxk8lPPq5Z6FYDq2QD5QphXEMudf641YzNxrI16jh91uqGRuM1zG5+lB4iD222rii0+qVfFlihAI5jLd3cBrTLXFFsMU65qt5zXDhCDh/Nb5V2LxSW1lOa78bda7QDgwDdid2b+91V9cq3ZDap5QlrJS3lOsept86ZssXIUu9vyc/UVx4M9/g+I/j8xWLx/K+8OC6UMg6TS5lYksHm47uvl73+v3UX88b20XXwUSiUf1Gf/bJbr9LvA+v66l0WJ5o99NT+xvJnp8nSXNwDLymKTs2b3n0olPk84Dfw5SXmbVDLUV15BKB+vr30tsSWiejvxgAbktWZG/ySOY1HPDfaq1e4iHvz//iOv6zm/0tBS6tJYHEj86F9xRn8lmgF1hapiF9U/54FNQUVvX6nrDBCDopodxe6wnZ/kpVdvV/AcTLW7AFFL8qYHKHLfXcQgybaa/FZOtQPEIMnCXj6ZYe0AMUgytgTcnnWD2tfIC5KqNdO4n6RBXutaQexriK3tqZpB0rPfPvV4sH/OvdjvcEHfY6cGgLWLGHgW5321dhJ/oxPOFHwCpb7M/2pE3vQA+anHg/0VDuz+PC/dI98Yp1KCQVJpY1ERqFLEBHP5qVTAG4PF7gW1mp3FexkVp8vMs2veAQQQB9q1nAjcPKZbOQpiX1NsMVIzMgEC54tXrnj1zEs3MBAnDbyyG6jTVb6NNh8Dx/4nDuQExNepJCZaIzmrSuIM1+l3xWC2rGs6UhxE3PYzeXrLieJEd34T9FMuQBwM22igeLWQktpd5Pci0xcDA8D/GzGgU7o9imUl8T5rmjp+BRxdmHdfr4KYWgPNC5kctdWHYnCmni/I2Bxo/VHB+VuME1sI80/cWJDGg8Wu+7pvygO1+m8D8SfEIEdzvJpXD6BxkNjCog7U7GuKLWrq31r1GJ+qzZXvJ6lJc7xl/pYk2ypAuynFmzG9IHZueeOm8lOpAP+vxZOF3Bzt5Rb2Yl01df4aOLm88Peswxdi62HryQXnaTlRDM7U4/GMzMS7HpRCKkF4kaHzr6/09HTY2toiLS0NNjZl9BJpIiJ6McdDxPuYefUE+q0B1vYRb9nRaUbRs6T/vUNsxXFqIAYtiWeB/r8UHNhQidDl+M2WJCIioueleTVw5kPdZknXXDd/SxKVCgySiIiInpd6DNF/18T71uVkFX+WdDt3cexS9rMba6sMXs1NlqnYOAUAERHR87KtJt6+5+kT8YbAQPFnSTcyEQMqtQrV9D/lA8kwSCIiInpehkZ5VwerZwfXZfoMpelXqNRgkERERPQiNIMbEyvdZklnkFSqMUgiIiJ6EZrBja6zpDswSCrNGCQRERG9CM3gRtdJWNmSVKoxSCIiInoRmsGNrrOkM0gq1TgFABER0Yuo4iPepsTRW/f7SdpUEW9BIuSK/1Opwhm3nxNn3CYiIip7dDl+s7uNiIiISAGDJCIiIiIFDJKIiIiIFDBIIiIiIlLAIImIiIhIAYMkIiIiIgUMkoiIiIgUMEgiIiIiUsAgiYiIiEgBgyQiIiIiBQySiIiIiBQwSCIiIiJSwCCJiIiISAGDJCIiIiIFRvouQFklCAIAID09Xc8lISIiouJSH7fVx/HCMEh6Tg8ePAAAVK1aVc8lISIiIl09ePAAtra2heZRCcUJpUhLbm4uEhISYG1tDZVKVaLbTk9PR9WqVXH79m3Y2NiU6LZLo9etvsDrV+fXrb7A61fn162+wOtX5/JSX0EQ8ODBA7i4uMDAoPBRR2xJek4GBgZwdXV9qfuwsbEp0x9EXb1u9QVevzq/bvUFXr86v271BV6/OpeH+hbVgqTGgdtEREREChgkERERESlgkFQKmZqa4quvvoKpqam+i/JKvG71BV6/Or9u9QVevzq/bvUFXr86v271BThwm4iIiEgRW5KIiIiIFDBIIiIiIlLAIImIiIhIAYMkIiIiIgUMkkqZZcuWwcPDA2ZmZvDx8cGRI0f0XaQSMWfOHDRp0gTW1taoXLkyevfujcuXL8vyCIKA6dOnw8XFBebm5mjXrh0uXLigpxKXvDlz5kClUiE4OFhKK291vnv3LgYNGgR7e3tYWFigUaNGiImJkZaXt/o+ffoUX3zxBTw8PGBubo7q1atj5syZyM3NlfKU9TofPnwYPXr0gIuLC1QqFbZt2yZbXpz6ZWZmYvz48XBwcIClpSV69uyJO3fuvMJaFF9h9c3Ozsann36K+vXrw9LSEi4uLhgyZAgSEhJk2yhL9QWKfo81jR49GiqVCosXL5all7U6FxeDpFJkw4YNCA4OxtSpU3HmzBm0bt0agYGBiI+P13fRXtihQ4fwwQcf4Pjx44iIiMDTp0/h7++PR48eSXnmz5+PhQsXYsmSJTh58iScnJzQuXNn6T55ZdnJkyfx008/oUGDBrL08lTne/fuoWXLljA2NsbOnTtx8eJFLFiwABUqVJDylKf6AsC8efPw448/YsmSJbh06RLmz5+Pb7/9Fj/88IOUp6zX+dGjR2jYsCGWLFmiuLw49QsODsbWrVsRHh6Oo0eP4uHDh+jevTtycnJeVTWKrbD6ZmRk4PTp05g2bRpOnz6NLVu24MqVK+jZs6csX1mqL1D0e6y2bds2nDhxAi4uLlrLylqdi02gUqNp06bCmDFjZGmenp7CZ599pqcSvTzJyckCAOHQoUOCIAhCbm6u4OTkJMydO1fK8+TJE8HW1lb48ccf9VXMEvHgwQOhVq1aQkREhNC2bVth4sSJgiCUvzp/+umnQqtWrQpcXt7qKwiC0K1bN2HYsGGytLfeeksYNGiQIAjlr84AhK1bt0rPi1O/+/fvC8bGxkJ4eLiU5+7du4KBgYGwa9euV1b255G/vkqio6MFAMKtW7cEQSjb9RWEgut8584doUqVKsL58+cFNzc3YdGiRdKysl7nwrAlqZTIyspCTEwM/P39Zen+/v6IjIzUU6lenrS0NABAxYoVAQA3btxAUlKSrP6mpqZo27Ztma//Bx98gG7duqFTp06y9PJW5+3bt8PX1xdvv/02KleujDfeeAPLly+Xlpe3+gJAq1atsG/fPly5cgUAcPbsWRw9ehRdu3YFUD7rrKk49YuJiUF2drYsj4uLC+rVq1cuXoO0tDSoVCqpxbQ81jc3NxeDBw/Gxx9/jLp162otL491VuMNbkuJlJQU5OTkwNHRUZbu6OiIpKQkPZXq5RAEAZMmTUKrVq1Qr149AJDqqFT/W7duvfIylpTw8HCcPn0aJ0+e1FpW3up8/fp1hISEYNKkSfj8888RHR2NCRMmwNTUFEOGDCl39QWATz/9FGlpafD09IShoSFycnLwzTffYMCAAQDK33ucX3Hql5SUBBMTE9jZ2WnlKeu/bU+ePMFnn32Gd999V7rha3ms77x582BkZIQJEyYoLi+PdVZjkFTKqFQq2XNBELTSyrpx48bhr7/+wtGjR7WWlaf63759GxMnTsSePXtgZmZWYL7yUufc3Fz4+vpi9uzZAIA33ngDFy5cQEhICIYMGSLlKy/1BcRxhGvXrsUvv/yCunXrIjY2FsHBwXBxcUFQUJCUrzzVWcnz1K+svwbZ2dno378/cnNzsWzZsiLzl9X6xsTE4H//+x9Onz6tc/nLap01sbutlHBwcIChoaFW1J2cnKx1llaWjR8/Htu3b8eBAwfg6uoqpTs5OQFAuap/TEwMkpOT4ePjAyMjIxgZGeHQoUP4/vvvYWRkJNWrvNTZ2dkZ3t7esjQvLy/pwoPy+B5//PHH+Oyzz9C/f3/Ur18fgwcPxocffog5c+YAKJ911lSc+jk5OSErKwv37t0rME9Zk52djXfeeQc3btxARESE1IoElL/6HjlyBMnJyahWrZr0O3br1i1MnjwZ7u7uAMpfnTUxSColTExM4OPjg4iICFl6REQE/Pz89FSqkiMIAsaNG4ctW7Zg//798PDwkC338PCAk5OTrP5ZWVk4dOhQma1/x44dce7cOcTGxkoPX19fDBw4ELGxsahevXq5qnPLli21pnW4cuUK3NzcAJTP9zgjIwMGBvKfUUNDQ2kKgPJYZ03FqZ+Pjw+MjY1leRITE3H+/Pky+RqoA6S4uDjs3bsX9vb2suXlrb6DBw/GX3/9Jfsdc3Fxwccff4zdu3cDKH91ltHTgHFSEB4eLhgbGwuhoaHCxYsXheDgYMHS0lK4efOmvov2wt5//33B1tZWOHjwoJCYmCg9MjIypDxz584VbG1thS1btgjnzp0TBgwYIDg7Owvp6el6LHnJ0ry6TRDKV52jo6MFIyMj4ZtvvhHi4uKEdevWCRYWFsLatWulPOWpvoIgCEFBQUKVKlWEP/74Q7hx44awZcsWwcHBQfjkk0+kPGW9zg8ePBDOnDkjnDlzRgAgLFy4UDhz5ox0NVdx6jdmzBjB1dVV2Lt3r3D69GmhQ4cOQsOGDYWnT5/qq1oFKqy+2dnZQs+ePQVXV1chNjZW9luWmZkpbaMs1VcQin6P88t/dZsglL06FxeDpFJm6dKlgpubm2BiYiI0btxYukS+rAOg+FixYoWUJzc3V/jqq68EJycnwdTUVGjTpo1w7tw5/RX6JcgfJJW3Ov/+++9CvXr1BFNTU8HT01P46aefZMvLW33T09OFiRMnCtWqVRPMzMyE6tWrC1OnTpUdMMt6nQ8cOKD43Q0KChIEoXj1e/z4sTBu3DihYsWKgrm5udC9e3chPj5eD7UpWmH1vXHjRoG/ZQcOHJC2UZbqKwhFv8f5KQVJZa3OxaUSBEF4FS1WRERERGUJxyQRERERKWCQRERERKSAQRIRERGRAgZJRERERAoYJBEREREpYJBEREREpIBBEhEREZECBklERCVEpVJh27Zt+i4GEZUQBklEVC4MHToUKpVK69GlSxd9F42IyigjfReAiKikdOnSBStWrJClmZqa6qk0RFTWsSWJiMoNU1NTODk5yR52dnYAxK6wkJAQBAYGwtzcHB4eHti0aZNs/XPnzqFDhw4wNzeHvb09Ro0ahYcPH8ryhIWFoW7dujA1NYWzszPGjRsnW56SkoI333wTFhYWqFWrFrZv3/5yK01ELw2DJCJ6bUybNg19+vTB2bNnMWjQIAwYMACXLl0CAGRkZKBLly6ws7PDyZMnsWnTJuzdu1cWBIWEhOCDDz7AqFGjcO7cOWzfvh01a9aU7WPGjBl455138Ndff6Fr164YOHAg/vvvv1daTyIqIfq+wy4RUUkICgoSDA0NBUtLS9lj5syZgiAIAgBhzJgxsnWaNWsmvP/++4IgCMJPP/0k2NnZCQ8fPpSW//nnn4KBgYGQlJQkCIIguLi4CFOnTi2wDACEL774Qnr+8OFDQaVSCTt37iyxehLRq8MxSURUbrRv3x4hISGytIoVK0r/t2jRQrasRYsWiI2NBQBcunQJDRs2hKWlpbS8ZcuWyM3NxeXLl6FSqZCQkICOHTsWWoYGDRpI/1taWsLa2hrJycnPWyUi0iMGSURUblhaWmp1fxVFpVIBAARBkP5XymNubl6s7RkbG2utm5ubq1OZiKh04JgkInptHD9+XOu5p6cnAMDb2xuxsbF49OiRtPzYsWMwMDBA7dq1YW1tDXd3d+zbt++VlpmI9IctSURUbmRmZiIpKUmWZmRkBAcHBwDApk2b4Ovri1atWmHdunWIjo5GaGgoAGDgwIH46quvEBQUhOnTp+Pff//F+PHjMXjwYDg6OgIApk+fjjFjxqBy5coIDAzEgwcPcOzYMYwfP/7VVpSIXgkGSURUbuzatQvOzs6ytDp16uDvv/8GIF55Fh4ejrFjx8LJyQnr1q2Dt7c3AMDCwgK7d+/GxIkT0aRJE1hYWKBPnz5YuHChtK2goCA8efIEixYtwkcffQQHBwf07dv31VWQiF4plSAIgr4LQUT0sqlUKmzduhW9e/fWd1GIqIzgmCQiIiIiBQySiIiIiBRwTBIRvRY4soCIdMWWJCIiIiIFDJKIiIiIFDBIIiIiIlLAIImIiIhIAYMkIiIiIgUMkoiIiIgUMEgiIiIiUsAgiYiIiEgBgyQiIiIiBf8Pg8ORDHK+ziAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train the model and collect the history\n",
    "history = model.fit(X_train, y_train, epochs=150, batch_size=15, validation_data=(X_test, y_test))\n",
    "\n",
    "# Get the accuracy scores\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Plot the accuracy scores\n",
    "plt.plot(train_accuracy, label='Training Accuracy')\n",
    "plt.plot(val_accuracy, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149d78f8",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "c14df786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "31/31 [==============================] - 2s 8ms/step - loss: 0.6629 - accuracy: 0.6450\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.5818 - accuracy: 0.6900\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.5430 - accuracy: 0.7237\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.5277 - accuracy: 0.7362\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.5203 - accuracy: 0.7538\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.5121 - accuracy: 0.7513\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.5028 - accuracy: 0.7550\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4994 - accuracy: 0.7575\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4932 - accuracy: 0.7700\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4924 - accuracy: 0.7638\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4850 - accuracy: 0.7713\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.4786 - accuracy: 0.7713\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4711 - accuracy: 0.7750\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4656 - accuracy: 0.7862\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4609 - accuracy: 0.7887\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4550 - accuracy: 0.7862\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4447 - accuracy: 0.7975\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4417 - accuracy: 0.8075\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4380 - accuracy: 0.8087\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4324 - accuracy: 0.7987\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4182 - accuracy: 0.8163\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.4064 - accuracy: 0.8112\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3996 - accuracy: 0.8238\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3900 - accuracy: 0.8313\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3900 - accuracy: 0.8288\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3969 - accuracy: 0.8250\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3744 - accuracy: 0.8350\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3679 - accuracy: 0.8413\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.3649 - accuracy: 0.8350\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.3649 - accuracy: 0.8288\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.3707 - accuracy: 0.8425\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.3544 - accuracy: 0.8425\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3387 - accuracy: 0.8562\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.3313 - accuracy: 0.8512\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.3295 - accuracy: 0.8575\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.3193 - accuracy: 0.8612\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.3215 - accuracy: 0.8587\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.3238 - accuracy: 0.8562\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.3100 - accuracy: 0.8625\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3142 - accuracy: 0.8637\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3107 - accuracy: 0.8662\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3053 - accuracy: 0.8662\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2987 - accuracy: 0.8625\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.3036 - accuracy: 0.8650\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2973 - accuracy: 0.8650\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2956 - accuracy: 0.8700\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2919 - accuracy: 0.8687\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2873 - accuracy: 0.8750\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2892 - accuracy: 0.8712\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2797 - accuracy: 0.8825\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2858 - accuracy: 0.8788\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2833 - accuracy: 0.8725\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2809 - accuracy: 0.8750\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2806 - accuracy: 0.8750\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2789 - accuracy: 0.8788\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2777 - accuracy: 0.8875\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2806 - accuracy: 0.8788\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2843 - accuracy: 0.8712\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2763 - accuracy: 0.8813\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2813 - accuracy: 0.8737\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2759 - accuracy: 0.8725\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2691 - accuracy: 0.8775\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2702 - accuracy: 0.8763\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2706 - accuracy: 0.8712\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2792 - accuracy: 0.8687\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2684 - accuracy: 0.8788\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2630 - accuracy: 0.8813\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2578 - accuracy: 0.8850\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2630 - accuracy: 0.8813\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2623 - accuracy: 0.8850\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2600 - accuracy: 0.8825\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2591 - accuracy: 0.8875\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2633 - accuracy: 0.8800\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2565 - accuracy: 0.8813\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2539 - accuracy: 0.8875\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2585 - accuracy: 0.8888\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2667 - accuracy: 0.8850\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2647 - accuracy: 0.8875\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2508 - accuracy: 0.8900\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2543 - accuracy: 0.8863\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2508 - accuracy: 0.8813\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2506 - accuracy: 0.8900\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2461 - accuracy: 0.8938\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2475 - accuracy: 0.8913\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2412 - accuracy: 0.8900\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2530 - accuracy: 0.8888\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2504 - accuracy: 0.8825\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2497 - accuracy: 0.8875\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2524 - accuracy: 0.8850\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2427 - accuracy: 0.8950\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2384 - accuracy: 0.8975\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2338 - accuracy: 0.8963\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2338 - accuracy: 0.8925\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2346 - accuracy: 0.9013\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2300 - accuracy: 0.8950\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2320 - accuracy: 0.8950\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2264 - accuracy: 0.8988\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2288 - accuracy: 0.9025\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2211 - accuracy: 0.9075\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2234 - accuracy: 0.9038\n"
     ]
    }
   ],
   "source": [
    "# Create the RNN model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Reshape the input data to include the time step dimension\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=26)\n",
    "model.save('RNNmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "771433c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step - loss: 1.8396 - accuracy: 0.8150\n",
      "Test Loss: 1.8396204710006714\n",
      "Test Accuracy: 81.49999976158142\n",
      "7/7 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy*100)\n",
    "\n",
    "# Predict on new data\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c44d8e",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "1e21556a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.6245 - accuracy: 0.6625\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.8112\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.3826 - accuracy: 0.8537\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.3463 - accuracy: 0.8662\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.3263 - accuracy: 0.8700\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.8725\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.8687\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.3054 - accuracy: 0.8737\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.3019 - accuracy: 0.8712\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2982 - accuracy: 0.8725\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2957 - accuracy: 0.8750\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2934 - accuracy: 0.8712\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2913 - accuracy: 0.8737\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2889 - accuracy: 0.8712\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2872 - accuracy: 0.8712\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2851 - accuracy: 0.8775\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2835 - accuracy: 0.8737\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2815 - accuracy: 0.8788\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2813 - accuracy: 0.8800\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2782 - accuracy: 0.8825\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2774 - accuracy: 0.8825\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2753 - accuracy: 0.8813\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2739 - accuracy: 0.8825\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2730 - accuracy: 0.8800\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2722 - accuracy: 0.8813\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2706 - accuracy: 0.8813\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2686 - accuracy: 0.8863\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2675 - accuracy: 0.8888\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2667 - accuracy: 0.8863\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2655 - accuracy: 0.8850\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2646 - accuracy: 0.8850\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2621 - accuracy: 0.8875\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2622 - accuracy: 0.8875\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2615 - accuracy: 0.8900\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2595 - accuracy: 0.8888\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2588 - accuracy: 0.8925\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2575 - accuracy: 0.8925\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2574 - accuracy: 0.8850\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2557 - accuracy: 0.8913\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2550 - accuracy: 0.8925\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2541 - accuracy: 0.8938\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.8925\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2515 - accuracy: 0.8913\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.8900\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.8925\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.8963\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2480 - accuracy: 0.8950\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.8975\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.8938\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2449 - accuracy: 0.8950\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.8963\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2434 - accuracy: 0.8925\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2418 - accuracy: 0.8963\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2417 - accuracy: 0.8963\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2401 - accuracy: 0.8975\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2397 - accuracy: 0.8975\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2392 - accuracy: 0.8988\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2386 - accuracy: 0.8988\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2376 - accuracy: 0.9025\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2366 - accuracy: 0.8975\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2356 - accuracy: 0.8988\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2342 - accuracy: 0.8988\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2339 - accuracy: 0.8988\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2349 - accuracy: 0.9025\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2337 - accuracy: 0.8988\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2325 - accuracy: 0.9050\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2309 - accuracy: 0.9000\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2292 - accuracy: 0.9013\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2289 - accuracy: 0.9025\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2276 - accuracy: 0.9038\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2264 - accuracy: 0.9038\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2247 - accuracy: 0.9075\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2250 - accuracy: 0.9025\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2241 - accuracy: 0.9025\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2229 - accuracy: 0.9062\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2226 - accuracy: 0.9025\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2202 - accuracy: 0.9062\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2198 - accuracy: 0.9087\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2188 - accuracy: 0.9075\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2176 - accuracy: 0.9087\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2164 - accuracy: 0.9112\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2157 - accuracy: 0.9087\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2151 - accuracy: 0.9087\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2135 - accuracy: 0.9087\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2121 - accuracy: 0.9100\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2107 - accuracy: 0.9087\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2103 - accuracy: 0.9137\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2090 - accuracy: 0.9100\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2080 - accuracy: 0.9125\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2075 - accuracy: 0.9137\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2059 - accuracy: 0.9112\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2051 - accuracy: 0.9137\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2043 - accuracy: 0.9125\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2025 - accuracy: 0.9137\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2013 - accuracy: 0.9137\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2010 - accuracy: 0.9150\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2000 - accuracy: 0.9137\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1981 - accuracy: 0.9187\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1985 - accuracy: 0.9200\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1973 - accuracy: 0.9162\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3543 - accuracy: 0.8400\n",
      "Test Loss: 0.35432034730911255\n",
      "Test Accuracy: 83.99999737739563\n",
      "7/7 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=26)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy*100)\n",
    "\n",
    "# Predict on new data\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36b7052",
   "metadata": {},
   "source": [
    "## ANN and CNN combined "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "d07ab282",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "31/31 [==============================] - 1s 3ms/step - loss: 0.4086 - accuracy: 0.8487\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.3237 - accuracy: 0.8600\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2995 - accuracy: 0.8925\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2896 - accuracy: 0.8863\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2743 - accuracy: 0.8875\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2756 - accuracy: 0.8913\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2588 - accuracy: 0.8863\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2528 - accuracy: 0.8963\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.8950\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2456 - accuracy: 0.8975\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2268 - accuracy: 0.9038\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2227 - accuracy: 0.9075\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2159 - accuracy: 0.9087\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2033 - accuracy: 0.9175\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2017 - accuracy: 0.9150\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1888 - accuracy: 0.9200\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1839 - accuracy: 0.9225\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1731 - accuracy: 0.9325\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1633 - accuracy: 0.9337\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1656 - accuracy: 0.9350\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1573 - accuracy: 0.9375\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1430 - accuracy: 0.9500\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1352 - accuracy: 0.9563\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1265 - accuracy: 0.9600\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1213 - accuracy: 0.9638\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1161 - accuracy: 0.9650\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1060 - accuracy: 0.9650\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1015 - accuracy: 0.9663\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0917 - accuracy: 0.9775\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0891 - accuracy: 0.9725\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0853 - accuracy: 0.9737\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0893 - accuracy: 0.9725\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.9775\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.9800\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.9875\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0708 - accuracy: 0.9787\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.9925\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9875\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.9912\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.9912\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0411 - accuracy: 0.9937\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9887\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0361 - accuracy: 0.9925\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0335 - accuracy: 0.9937\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0324 - accuracy: 0.9950\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0266 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0273 - accuracy: 0.9950\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0252 - accuracy: 0.9987\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0174 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 0.9987\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0126 - accuracy: 0.9987\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.8902 - accuracy: 0.8350\n",
      "Test Loss: 0.8902396559715271\n",
      "Test Accuracy: 83.49999785423279\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "# Create the ANN model\n",
    "ann_model = Sequential()\n",
    "ann_model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "\n",
    "# Create the CNN model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "cnn_model.add(Flatten())\n",
    "\n",
    "# Combine the ANN and CNN models\n",
    "combined_input = concatenate([ann_model.output, cnn_model.output])\n",
    "combined_output = Dense(128, activation='relu')(combined_input)\n",
    "combined_output = Dense(2, activation='softmax')(combined_output)\n",
    "\n",
    "# Create the final model\n",
    "combined_model = Model(inputs=[ann_model.input, cnn_model.input], outputs=combined_output)\n",
    "\n",
    "# Compile the model\n",
    "combined_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "combined_model.fit([X_train, X_train[..., None]], y_train, epochs=100, batch_size=26)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = combined_model.evaluate([X_test, X_test[..., None]], y_test)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy*100)\n",
    "model.save('ANN-CNN-model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266fc71a",
   "metadata": {},
   "source": [
    "# DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "f82e16a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "31/31 [==============================] - 1s 3ms/step - loss: 0.5179 - accuracy: 0.7663\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.3515 - accuracy: 0.8712\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.3119 - accuracy: 0.8687\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.3020 - accuracy: 0.8737\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2893 - accuracy: 0.8863\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2803 - accuracy: 0.8800\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2749 - accuracy: 0.8900\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2619 - accuracy: 0.9013\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.8925\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.8963\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2266 - accuracy: 0.9000\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2187 - accuracy: 0.8988\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2165 - accuracy: 0.9075\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2181 - accuracy: 0.9075\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2038 - accuracy: 0.9112\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1842 - accuracy: 0.9225\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1864 - accuracy: 0.9212\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1633 - accuracy: 0.9388\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1549 - accuracy: 0.9388\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9450\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1594 - accuracy: 0.9312\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1645 - accuracy: 0.9350\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1354 - accuracy: 0.9450\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1162 - accuracy: 0.9563\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1221 - accuracy: 0.9538\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1045 - accuracy: 0.9600\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1083 - accuracy: 0.9638\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1181 - accuracy: 0.9525\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0874 - accuracy: 0.9600\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0912 - accuracy: 0.9575\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1116 - accuracy: 0.9550\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0878 - accuracy: 0.9725\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0786 - accuracy: 0.9688\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0961 - accuracy: 0.9600\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0754 - accuracy: 0.9688\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0773 - accuracy: 0.9675\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.9800\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0826 - accuracy: 0.9737\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0853 - accuracy: 0.9725\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.9775\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9787\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.9762\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9850\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 0.9887\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.9812\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0379 - accuracy: 0.9837\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0371 - accuracy: 0.9837\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9812\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9837\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9800\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0401 - accuracy: 0.9875\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0371 - accuracy: 0.9900\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0498 - accuracy: 0.9787\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0469 - accuracy: 0.9812\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9850\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 0.9900\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0264 - accuracy: 0.9937\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0369 - accuracy: 0.9837\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0563 - accuracy: 0.9800\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0445 - accuracy: 0.9850\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 0.9925\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0323 - accuracy: 0.9912\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 0.9950\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0352 - accuracy: 0.9912\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0302 - accuracy: 0.9887\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0267 - accuracy: 0.9887\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0344 - accuracy: 0.9887\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0313 - accuracy: 0.9900\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0335 - accuracy: 0.9900\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0309 - accuracy: 0.9887\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 0.9925\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 0.9900\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0241 - accuracy: 0.9875\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.9862\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0231 - accuracy: 0.9925\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0187 - accuracy: 0.9925\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 0.9950\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 0.9937\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0189 - accuracy: 0.9925\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0158 - accuracy: 0.9987\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0265 - accuracy: 0.9950\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0310 - accuracy: 0.9900\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9962\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0233 - accuracy: 0.9900\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 0.9962\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0197 - accuracy: 0.9937\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0179 - accuracy: 0.9962\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0170 - accuracy: 0.9925\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 0.9975\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 0.9900\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0183 - accuracy: 0.9937\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 0.9987\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0159 - accuracy: 0.9962\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0214 - accuracy: 0.9937\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0424 - accuracy: 0.9887\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0154 - accuracy: 0.9950\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0195 - accuracy: 0.9950\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0126 - accuracy: 0.9962\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0155 - accuracy: 0.9937\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0195 - accuracy: 0.9937\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4084 - accuracy: 0.8350\n",
      "Test Loss: 1.4083808660507202\n",
      "Test Accuracy: 83.49999785423279\n"
     ]
    }
   ],
   "source": [
    "# Create the DNN model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))  # Dropout layer to reduce overfitting\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))  # Dropout layer to reduce overfitting\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=26)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy*100)\n",
    "model.save('DNN-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "c54a0ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1573ad1",
   "metadata": {},
   "source": [
    "# ANN -DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "bfe84322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 [==============================] - 1s 6ms/step - loss: 0.7993 - accuracy: 0.5250 - val_loss: 0.5881 - val_accuracy: 0.7063\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5910 - accuracy: 0.6797 - val_loss: 0.4615 - val_accuracy: 0.8313\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.7859 - val_loss: 0.4108 - val_accuracy: 0.8500\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.8125 - val_loss: 0.3863 - val_accuracy: 0.8562\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4004 - accuracy: 0.8625 - val_loss: 0.3740 - val_accuracy: 0.8562\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3778 - accuracy: 0.8531 - val_loss: 0.3675 - val_accuracy: 0.8625\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3607 - accuracy: 0.8547 - val_loss: 0.3617 - val_accuracy: 0.8625\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3696 - accuracy: 0.8578 - val_loss: 0.3621 - val_accuracy: 0.8750\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3464 - accuracy: 0.8813 - val_loss: 0.3622 - val_accuracy: 0.8687\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3400 - accuracy: 0.8672 - val_loss: 0.3623 - val_accuracy: 0.8687\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3820 - accuracy: 0.8625 - val_loss: 0.3554 - val_accuracy: 0.8687\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3077 - accuracy: 0.8828 - val_loss: 0.3582 - val_accuracy: 0.8687\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3509 - accuracy: 0.8531 - val_loss: 0.3573 - val_accuracy: 0.8687\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3353 - accuracy: 0.8750 - val_loss: 0.3530 - val_accuracy: 0.8625\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3628 - accuracy: 0.8641 - val_loss: 0.3523 - val_accuracy: 0.8625\n",
      "Epoch 16/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3291 - accuracy: 0.8750 - val_loss: 0.3547 - val_accuracy: 0.8687\n",
      "Epoch 17/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3216 - accuracy: 0.8813 - val_loss: 0.3500 - val_accuracy: 0.8625\n",
      "Epoch 18/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3126 - accuracy: 0.8859 - val_loss: 0.3494 - val_accuracy: 0.8687\n",
      "Epoch 19/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3220 - accuracy: 0.8703 - val_loss: 0.3484 - val_accuracy: 0.8687\n",
      "Epoch 20/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3172 - accuracy: 0.8703 - val_loss: 0.3535 - val_accuracy: 0.8687\n",
      "Epoch 21/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3240 - accuracy: 0.8656 - val_loss: 0.3529 - val_accuracy: 0.8687\n",
      "Epoch 22/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3212 - accuracy: 0.8828 - val_loss: 0.3568 - val_accuracy: 0.8687\n",
      "Epoch 23/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3052 - accuracy: 0.8766 - val_loss: 0.3531 - val_accuracy: 0.8687\n",
      "Epoch 24/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2966 - accuracy: 0.8859 - val_loss: 0.3533 - val_accuracy: 0.8687\n",
      "Epoch 25/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3048 - accuracy: 0.8844 - val_loss: 0.3503 - val_accuracy: 0.8687\n",
      "Epoch 26/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3111 - accuracy: 0.8750 - val_loss: 0.3531 - val_accuracy: 0.8687\n",
      "Epoch 27/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3374 - accuracy: 0.8766 - val_loss: 0.3483 - val_accuracy: 0.8687\n",
      "Epoch 28/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2997 - accuracy: 0.8859 - val_loss: 0.3468 - val_accuracy: 0.8687\n",
      "Epoch 29/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3050 - accuracy: 0.8875 - val_loss: 0.3490 - val_accuracy: 0.8625\n",
      "Epoch 30/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2823 - accuracy: 0.8859 - val_loss: 0.3543 - val_accuracy: 0.8687\n",
      "Epoch 31/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3016 - accuracy: 0.8797 - val_loss: 0.3532 - val_accuracy: 0.8687\n",
      "Epoch 32/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3013 - accuracy: 0.8875 - val_loss: 0.3534 - val_accuracy: 0.8687\n",
      "Epoch 33/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2889 - accuracy: 0.8891 - val_loss: 0.3494 - val_accuracy: 0.8687\n",
      "Epoch 34/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2746 - accuracy: 0.8859 - val_loss: 0.3512 - val_accuracy: 0.8687\n",
      "Epoch 35/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3156 - accuracy: 0.8828 - val_loss: 0.3481 - val_accuracy: 0.8687\n",
      "Epoch 36/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2802 - accuracy: 0.8859 - val_loss: 0.3469 - val_accuracy: 0.8687\n",
      "Epoch 37/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2890 - accuracy: 0.8719 - val_loss: 0.3532 - val_accuracy: 0.8625\n",
      "Epoch 38/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3096 - accuracy: 0.8766 - val_loss: 0.3440 - val_accuracy: 0.8625\n",
      "Epoch 39/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2813 - accuracy: 0.8969 - val_loss: 0.3412 - val_accuracy: 0.8687\n",
      "Epoch 40/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2883 - accuracy: 0.8875 - val_loss: 0.3428 - val_accuracy: 0.8687\n",
      "Epoch 41/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2728 - accuracy: 0.8875 - val_loss: 0.3469 - val_accuracy: 0.8687\n",
      "Epoch 42/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2942 - accuracy: 0.8797 - val_loss: 0.3445 - val_accuracy: 0.8625\n",
      "Epoch 43/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3034 - accuracy: 0.8813 - val_loss: 0.3440 - val_accuracy: 0.8562\n",
      "Epoch 44/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2802 - accuracy: 0.8766 - val_loss: 0.3505 - val_accuracy: 0.8562\n",
      "Epoch 45/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2874 - accuracy: 0.8734 - val_loss: 0.3460 - val_accuracy: 0.8562\n",
      "Epoch 46/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3028 - accuracy: 0.8703 - val_loss: 0.3403 - val_accuracy: 0.8562\n",
      "Epoch 47/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2817 - accuracy: 0.8813 - val_loss: 0.3403 - val_accuracy: 0.8625\n",
      "Epoch 48/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2705 - accuracy: 0.8859 - val_loss: 0.3370 - val_accuracy: 0.8562\n",
      "Epoch 49/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2847 - accuracy: 0.8844 - val_loss: 0.3363 - val_accuracy: 0.8562\n",
      "Epoch 50/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2766 - accuracy: 0.8938 - val_loss: 0.3412 - val_accuracy: 0.8625\n",
      "Epoch 51/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2571 - accuracy: 0.8984 - val_loss: 0.3490 - val_accuracy: 0.8562\n",
      "Epoch 52/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2898 - accuracy: 0.8734 - val_loss: 0.3411 - val_accuracy: 0.8562\n",
      "Epoch 53/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2788 - accuracy: 0.8906 - val_loss: 0.3363 - val_accuracy: 0.8562\n",
      "Epoch 54/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2706 - accuracy: 0.8922 - val_loss: 0.3412 - val_accuracy: 0.8562\n",
      "Epoch 55/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2909 - accuracy: 0.8703 - val_loss: 0.3422 - val_accuracy: 0.8562\n",
      "Epoch 56/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2821 - accuracy: 0.8813 - val_loss: 0.3437 - val_accuracy: 0.8562\n",
      "Epoch 57/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2659 - accuracy: 0.8891 - val_loss: 0.3472 - val_accuracy: 0.8562\n",
      "Epoch 58/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2695 - accuracy: 0.8844 - val_loss: 0.3503 - val_accuracy: 0.8562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2721 - accuracy: 0.8891 - val_loss: 0.3374 - val_accuracy: 0.8562\n",
      "Epoch 60/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2680 - accuracy: 0.8906 - val_loss: 0.3432 - val_accuracy: 0.8562\n",
      "Epoch 61/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2690 - accuracy: 0.8844 - val_loss: 0.3461 - val_accuracy: 0.8500\n",
      "Epoch 62/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2715 - accuracy: 0.9000 - val_loss: 0.3379 - val_accuracy: 0.8500\n",
      "Epoch 63/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2560 - accuracy: 0.8781 - val_loss: 0.3452 - val_accuracy: 0.8500\n",
      "Epoch 64/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2744 - accuracy: 0.8875 - val_loss: 0.3434 - val_accuracy: 0.8500\n",
      "Epoch 65/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2653 - accuracy: 0.8938 - val_loss: 0.3443 - val_accuracy: 0.8500\n",
      "Epoch 66/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2674 - accuracy: 0.8719 - val_loss: 0.3414 - val_accuracy: 0.8500\n",
      "Epoch 67/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2734 - accuracy: 0.8766 - val_loss: 0.3439 - val_accuracy: 0.8500\n",
      "Epoch 68/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2584 - accuracy: 0.8906 - val_loss: 0.3456 - val_accuracy: 0.8500\n",
      "Epoch 69/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2760 - accuracy: 0.8906 - val_loss: 0.3452 - val_accuracy: 0.8500\n",
      "Epoch 70/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2608 - accuracy: 0.8875 - val_loss: 0.3461 - val_accuracy: 0.8500\n",
      "Epoch 71/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2257 - accuracy: 0.8922 - val_loss: 0.3534 - val_accuracy: 0.8562\n",
      "Epoch 72/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.8922 - val_loss: 0.3593 - val_accuracy: 0.8562\n",
      "Epoch 73/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2640 - accuracy: 0.8859 - val_loss: 0.3538 - val_accuracy: 0.8500\n",
      "Epoch 74/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2438 - accuracy: 0.9109 - val_loss: 0.3525 - val_accuracy: 0.8500\n",
      "Epoch 75/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2608 - accuracy: 0.8844 - val_loss: 0.3448 - val_accuracy: 0.8500\n",
      "Epoch 76/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2404 - accuracy: 0.9000 - val_loss: 0.3400 - val_accuracy: 0.8500\n",
      "Epoch 77/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2425 - accuracy: 0.8906 - val_loss: 0.3491 - val_accuracy: 0.8500\n",
      "Epoch 78/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2474 - accuracy: 0.8875 - val_loss: 0.3442 - val_accuracy: 0.8500\n",
      "Epoch 79/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.8922 - val_loss: 0.3444 - val_accuracy: 0.8500\n",
      "Epoch 80/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2413 - accuracy: 0.8984 - val_loss: 0.3423 - val_accuracy: 0.8500\n",
      "Epoch 81/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.8922 - val_loss: 0.3435 - val_accuracy: 0.8500\n",
      "Epoch 82/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2415 - accuracy: 0.8922 - val_loss: 0.3496 - val_accuracy: 0.8500\n",
      "Epoch 83/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2450 - accuracy: 0.8953 - val_loss: 0.3402 - val_accuracy: 0.8500\n",
      "Epoch 84/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2535 - accuracy: 0.8938 - val_loss: 0.3467 - val_accuracy: 0.8500\n",
      "Epoch 85/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2558 - accuracy: 0.9031 - val_loss: 0.3446 - val_accuracy: 0.8500\n",
      "Epoch 86/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2640 - accuracy: 0.8906 - val_loss: 0.3444 - val_accuracy: 0.8500\n",
      "Epoch 87/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2438 - accuracy: 0.8984 - val_loss: 0.3435 - val_accuracy: 0.8500\n",
      "Epoch 88/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2332 - accuracy: 0.9031 - val_loss: 0.3455 - val_accuracy: 0.8500\n",
      "Epoch 89/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2442 - accuracy: 0.8953 - val_loss: 0.3500 - val_accuracy: 0.8500\n",
      "Epoch 90/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2621 - accuracy: 0.8922 - val_loss: 0.3462 - val_accuracy: 0.8500\n",
      "Epoch 91/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2519 - accuracy: 0.8828 - val_loss: 0.3433 - val_accuracy: 0.8500\n",
      "Epoch 92/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2553 - accuracy: 0.8891 - val_loss: 0.3368 - val_accuracy: 0.8500\n",
      "Epoch 93/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2385 - accuracy: 0.9047 - val_loss: 0.3403 - val_accuracy: 0.8500\n",
      "Epoch 94/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2442 - accuracy: 0.8969 - val_loss: 0.3405 - val_accuracy: 0.8500\n",
      "Epoch 95/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2185 - accuracy: 0.9031 - val_loss: 0.3367 - val_accuracy: 0.8500\n",
      "Epoch 96/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2247 - accuracy: 0.9031 - val_loss: 0.3404 - val_accuracy: 0.8438\n",
      "Epoch 97/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2297 - accuracy: 0.8969 - val_loss: 0.3437 - val_accuracy: 0.8500\n",
      "Epoch 98/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2255 - accuracy: 0.9078 - val_loss: 0.3597 - val_accuracy: 0.8500\n",
      "Epoch 99/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2407 - accuracy: 0.8953 - val_loss: 0.3567 - val_accuracy: 0.8562\n",
      "Epoch 100/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2230 - accuracy: 0.9031 - val_loss: 0.3522 - val_accuracy: 0.8500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3873 - accuracy: 0.8550\n",
      "Test Loss: 0.38733211159706116\n",
      "Test Accuracy: 85.50000190734863\n"
     ]
    }
   ],
   "source": [
    "# Create the hybrid model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Define the optimizer with adjusted learning rate\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# Compile the model with the optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=16, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28c4610",
   "metadata": {},
   "source": [
    "# RNN-DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "c1d155cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 3s 30ms/step - loss: 0.6999 - accuracy: 0.4953 - val_loss: 0.6824 - val_accuracy: 0.5875\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.6801 - accuracy: 0.5859 - val_loss: 0.6761 - val_accuracy: 0.6000\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.6655 - accuracy: 0.5797 - val_loss: 0.6721 - val_accuracy: 0.6187\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.6646 - accuracy: 0.5984 - val_loss: 0.6592 - val_accuracy: 0.6250\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.6433 - accuracy: 0.6375 - val_loss: 0.6316 - val_accuracy: 0.6625\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.6031 - accuracy: 0.6656 - val_loss: 0.5993 - val_accuracy: 0.7000\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.5668 - accuracy: 0.6938 - val_loss: 0.5810 - val_accuracy: 0.7125\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.5501 - accuracy: 0.7109 - val_loss: 0.5838 - val_accuracy: 0.7375\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.5248 - accuracy: 0.7391 - val_loss: 0.5551 - val_accuracy: 0.7312\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.5150 - accuracy: 0.7484 - val_loss: 0.5519 - val_accuracy: 0.7437\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.4991 - accuracy: 0.7828 - val_loss: 0.5410 - val_accuracy: 0.7500\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.5013 - accuracy: 0.7750 - val_loss: 0.5209 - val_accuracy: 0.7688\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.4836 - accuracy: 0.7844 - val_loss: 0.5521 - val_accuracy: 0.7375\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.4889 - accuracy: 0.7797 - val_loss: 0.5011 - val_accuracy: 0.7812\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.4687 - accuracy: 0.7891 - val_loss: 0.5124 - val_accuracy: 0.7875\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.4697 - accuracy: 0.7937 - val_loss: 0.4956 - val_accuracy: 0.7750\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.4488 - accuracy: 0.7953 - val_loss: 0.5005 - val_accuracy: 0.7875\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.4344 - accuracy: 0.8016 - val_loss: 0.4830 - val_accuracy: 0.8000\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.4572 - accuracy: 0.7953 - val_loss: 0.4664 - val_accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.4454 - accuracy: 0.7984 - val_loss: 0.4641 - val_accuracy: 0.7937\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.4421 - accuracy: 0.8062 - val_loss: 0.4685 - val_accuracy: 0.8188\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.4392 - accuracy: 0.8094 - val_loss: 0.4632 - val_accuracy: 0.8250\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.4190 - accuracy: 0.8109 - val_loss: 0.4503 - val_accuracy: 0.8250\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.4256 - accuracy: 0.8219 - val_loss: 0.4534 - val_accuracy: 0.8125\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.4335 - accuracy: 0.8156 - val_loss: 0.4463 - val_accuracy: 0.8188\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.4165 - accuracy: 0.8344 - val_loss: 0.4347 - val_accuracy: 0.8250\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.4189 - accuracy: 0.8297 - val_loss: 0.4526 - val_accuracy: 0.8188\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.4168 - accuracy: 0.8297 - val_loss: 0.4389 - val_accuracy: 0.8250\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.4160 - accuracy: 0.8266 - val_loss: 0.4388 - val_accuracy: 0.8250\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.4031 - accuracy: 0.8359 - val_loss: 0.4300 - val_accuracy: 0.8188\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.4090 - accuracy: 0.8141 - val_loss: 0.4204 - val_accuracy: 0.8313\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.3881 - accuracy: 0.8125 - val_loss: 0.4275 - val_accuracy: 0.8125\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.3894 - accuracy: 0.8297 - val_loss: 0.4242 - val_accuracy: 0.8313\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.3871 - accuracy: 0.8328 - val_loss: 0.4180 - val_accuracy: 0.8313\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.3872 - accuracy: 0.8281 - val_loss: 0.4146 - val_accuracy: 0.8250\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.3951 - accuracy: 0.8297 - val_loss: 0.4222 - val_accuracy: 0.8188\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.3641 - accuracy: 0.8453 - val_loss: 0.4171 - val_accuracy: 0.8250\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.3822 - accuracy: 0.8188 - val_loss: 0.4250 - val_accuracy: 0.8313\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.3792 - accuracy: 0.8375 - val_loss: 0.4140 - val_accuracy: 0.8250\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.3421 - accuracy: 0.8641 - val_loss: 0.4087 - val_accuracy: 0.8438\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.3639 - accuracy: 0.8406 - val_loss: 0.4113 - val_accuracy: 0.8062\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.3634 - accuracy: 0.8203 - val_loss: 0.3983 - val_accuracy: 0.8250\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.3696 - accuracy: 0.8375 - val_loss: 0.4309 - val_accuracy: 0.8125\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.3556 - accuracy: 0.8375 - val_loss: 0.4051 - val_accuracy: 0.8250\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.3400 - accuracy: 0.8547 - val_loss: 0.4021 - val_accuracy: 0.8500\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.3398 - accuracy: 0.8703 - val_loss: 0.4091 - val_accuracy: 0.8375\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.3577 - accuracy: 0.8422 - val_loss: 0.3942 - val_accuracy: 0.8375\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.3418 - accuracy: 0.8484 - val_loss: 0.3910 - val_accuracy: 0.8250\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.3545 - accuracy: 0.8203 - val_loss: 0.3994 - val_accuracy: 0.8375\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.3481 - accuracy: 0.8562 - val_loss: 0.3857 - val_accuracy: 0.8250\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.3384 - accuracy: 0.8438 - val_loss: 0.3840 - val_accuracy: 0.8250\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.3359 - accuracy: 0.8375 - val_loss: 0.3937 - val_accuracy: 0.8250\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.3309 - accuracy: 0.8484 - val_loss: 0.3891 - val_accuracy: 0.8250\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.3128 - accuracy: 0.8594 - val_loss: 0.3867 - val_accuracy: 0.8313\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.3230 - accuracy: 0.8484 - val_loss: 0.3958 - val_accuracy: 0.8188\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.3248 - accuracy: 0.8484 - val_loss: 0.3855 - val_accuracy: 0.8313\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.3298 - accuracy: 0.8438 - val_loss: 0.3687 - val_accuracy: 0.8188\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.3020 - accuracy: 0.8656 - val_loss: 0.3639 - val_accuracy: 0.8313\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.3069 - accuracy: 0.8562 - val_loss: 0.3823 - val_accuracy: 0.8250\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.3167 - accuracy: 0.8469 - val_loss: 0.3890 - val_accuracy: 0.8250\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.3220 - accuracy: 0.8531 - val_loss: 0.3733 - val_accuracy: 0.8250\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.3042 - accuracy: 0.8750 - val_loss: 0.3740 - val_accuracy: 0.8375\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.2921 - accuracy: 0.8703 - val_loss: 0.3664 - val_accuracy: 0.8375\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.2937 - accuracy: 0.8578 - val_loss: 0.3675 - val_accuracy: 0.8375\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.2992 - accuracy: 0.8687 - val_loss: 0.3738 - val_accuracy: 0.8313\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.2862 - accuracy: 0.8734 - val_loss: 0.3687 - val_accuracy: 0.8375\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.2847 - accuracy: 0.8750 - val_loss: 0.3575 - val_accuracy: 0.8313\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.2989 - accuracy: 0.8797 - val_loss: 0.3547 - val_accuracy: 0.8250\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.3052 - accuracy: 0.8672 - val_loss: 0.3725 - val_accuracy: 0.8375\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.2912 - accuracy: 0.8609 - val_loss: 0.3896 - val_accuracy: 0.8375\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.2774 - accuracy: 0.8781 - val_loss: 0.3388 - val_accuracy: 0.8375\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.2717 - accuracy: 0.8719 - val_loss: 0.3931 - val_accuracy: 0.8188\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.2625 - accuracy: 0.8891 - val_loss: 0.4011 - val_accuracy: 0.8438\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.3023 - accuracy: 0.8641 - val_loss: 0.3607 - val_accuracy: 0.8313\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.2783 - accuracy: 0.8562 - val_loss: 0.3865 - val_accuracy: 0.7875\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.2703 - accuracy: 0.8672 - val_loss: 0.3713 - val_accuracy: 0.8375\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.2590 - accuracy: 0.8813 - val_loss: 0.3746 - val_accuracy: 0.8250\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.2714 - accuracy: 0.8750 - val_loss: 0.3823 - val_accuracy: 0.8250\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.2621 - accuracy: 0.8781 - val_loss: 0.3798 - val_accuracy: 0.8313\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.2544 - accuracy: 0.8813 - val_loss: 0.3638 - val_accuracy: 0.8250\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.2655 - accuracy: 0.8922 - val_loss: 0.3715 - val_accuracy: 0.8250\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.2666 - accuracy: 0.8859 - val_loss: 0.3825 - val_accuracy: 0.8438\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.2505 - accuracy: 0.8891 - val_loss: 0.3973 - val_accuracy: 0.8250\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.2663 - accuracy: 0.8922 - val_loss: 0.3699 - val_accuracy: 0.8375\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.2446 - accuracy: 0.8906 - val_loss: 0.3620 - val_accuracy: 0.8375\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.2479 - accuracy: 0.8844 - val_loss: 0.4095 - val_accuracy: 0.8125\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.2615 - accuracy: 0.8781 - val_loss: 0.4088 - val_accuracy: 0.8313\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.2408 - accuracy: 0.8953 - val_loss: 0.3815 - val_accuracy: 0.8313\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.2447 - accuracy: 0.8969 - val_loss: 0.3819 - val_accuracy: 0.8375\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.2389 - accuracy: 0.8969 - val_loss: 0.3978 - val_accuracy: 0.8375\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.2414 - accuracy: 0.8906 - val_loss: 0.3795 - val_accuracy: 0.8562\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.2597 - accuracy: 0.8844 - val_loss: 0.3694 - val_accuracy: 0.8438\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.2380 - accuracy: 0.8969 - val_loss: 0.3744 - val_accuracy: 0.8250\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.2522 - accuracy: 0.8906 - val_loss: 0.4173 - val_accuracy: 0.8375\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.2266 - accuracy: 0.8906 - val_loss: 0.3983 - val_accuracy: 0.8250\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.2324 - accuracy: 0.8906 - val_loss: 0.4318 - val_accuracy: 0.8188\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.2332 - accuracy: 0.9016 - val_loss: 0.3794 - val_accuracy: 0.8375\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.2413 - accuracy: 0.8969 - val_loss: 0.3853 - val_accuracy: 0.8313\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.2160 - accuracy: 0.9141 - val_loss: 0.3624 - val_accuracy: 0.8438\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.2422 - accuracy: 0.9000 - val_loss: 0.3737 - val_accuracy: 0.8313\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3690 - accuracy: 0.8600\n",
      "Test Loss: 0.3689941167831421\n",
      "Test Accuracy: 86.00000143051147\n"
     ]
    }
   ],
   "source": [
    "# Create the hybrid model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Define the optimizer with adjusted learning rate\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# Compile the model with the optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=26, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy*100)\n",
    "model.save('RNN-DNNmodel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d6aca4",
   "metadata": {},
   "source": [
    "# CNN-DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "afe65840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 1s 10ms/step - loss: 0.6308 - accuracy: 0.6359 - val_loss: 0.4863 - val_accuracy: 0.7937\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5095 - accuracy: 0.7578 - val_loss: 0.4530 - val_accuracy: 0.8125\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4704 - accuracy: 0.7953 - val_loss: 0.4240 - val_accuracy: 0.8250\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4440 - accuracy: 0.8156 - val_loss: 0.4029 - val_accuracy: 0.8250\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.8078 - val_loss: 0.3853 - val_accuracy: 0.8438\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3899 - accuracy: 0.8281 - val_loss: 0.3667 - val_accuracy: 0.8438\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3669 - accuracy: 0.8438 - val_loss: 0.3611 - val_accuracy: 0.8313\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3731 - accuracy: 0.8516 - val_loss: 0.3529 - val_accuracy: 0.8562\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3685 - accuracy: 0.8406 - val_loss: 0.3526 - val_accuracy: 0.8375\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3595 - accuracy: 0.8391 - val_loss: 0.3484 - val_accuracy: 0.8562\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3434 - accuracy: 0.8641 - val_loss: 0.3539 - val_accuracy: 0.8438\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3530 - accuracy: 0.8672 - val_loss: 0.3400 - val_accuracy: 0.8562\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3489 - accuracy: 0.8438 - val_loss: 0.3401 - val_accuracy: 0.8625\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3487 - accuracy: 0.8625 - val_loss: 0.3487 - val_accuracy: 0.8562\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3622 - accuracy: 0.8531 - val_loss: 0.3366 - val_accuracy: 0.8500\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3412 - accuracy: 0.8641 - val_loss: 0.3472 - val_accuracy: 0.8438\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3486 - accuracy: 0.8594 - val_loss: 0.3412 - val_accuracy: 0.8625\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3360 - accuracy: 0.8625 - val_loss: 0.3375 - val_accuracy: 0.8562\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3431 - accuracy: 0.8516 - val_loss: 0.3333 - val_accuracy: 0.8562\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3408 - accuracy: 0.8641 - val_loss: 0.3306 - val_accuracy: 0.8562\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3204 - accuracy: 0.8734 - val_loss: 0.3359 - val_accuracy: 0.8562\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3162 - accuracy: 0.8656 - val_loss: 0.3389 - val_accuracy: 0.8625\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3112 - accuracy: 0.8672 - val_loss: 0.3339 - val_accuracy: 0.8562\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3230 - accuracy: 0.8609 - val_loss: 0.3402 - val_accuracy: 0.8625\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2994 - accuracy: 0.8875 - val_loss: 0.3325 - val_accuracy: 0.8687\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3240 - accuracy: 0.8766 - val_loss: 0.3574 - val_accuracy: 0.8625\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3083 - accuracy: 0.8703 - val_loss: 0.3638 - val_accuracy: 0.8625\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3021 - accuracy: 0.8750 - val_loss: 0.3535 - val_accuracy: 0.8625\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3260 - accuracy: 0.8828 - val_loss: 0.3439 - val_accuracy: 0.8625\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3080 - accuracy: 0.8750 - val_loss: 0.3385 - val_accuracy: 0.8562\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2891 - accuracy: 0.8797 - val_loss: 0.3438 - val_accuracy: 0.8625\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3337 - accuracy: 0.8656 - val_loss: 0.3475 - val_accuracy: 0.8625\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3060 - accuracy: 0.8781 - val_loss: 0.3493 - val_accuracy: 0.8562\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2947 - accuracy: 0.8797 - val_loss: 0.3398 - val_accuracy: 0.8625\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3141 - accuracy: 0.8719 - val_loss: 0.3552 - val_accuracy: 0.8625\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2947 - accuracy: 0.8797 - val_loss: 0.3485 - val_accuracy: 0.8625\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2926 - accuracy: 0.8906 - val_loss: 0.3378 - val_accuracy: 0.8562\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3017 - accuracy: 0.8781 - val_loss: 0.3599 - val_accuracy: 0.8625\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3007 - accuracy: 0.8734 - val_loss: 0.3398 - val_accuracy: 0.8500\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2877 - accuracy: 0.8750 - val_loss: 0.3467 - val_accuracy: 0.8562\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2888 - accuracy: 0.8922 - val_loss: 0.3610 - val_accuracy: 0.8625\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2897 - accuracy: 0.8750 - val_loss: 0.3365 - val_accuracy: 0.8687\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3244 - accuracy: 0.8781 - val_loss: 0.3521 - val_accuracy: 0.8562\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.2880 - accuracy: 0.8797 - val_loss: 0.3579 - val_accuracy: 0.8500\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2714 - accuracy: 0.8875 - val_loss: 0.3441 - val_accuracy: 0.8625\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2905 - accuracy: 0.8844 - val_loss: 0.3538 - val_accuracy: 0.8375\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2896 - accuracy: 0.8797 - val_loss: 0.3501 - val_accuracy: 0.8625\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2899 - accuracy: 0.8875 - val_loss: 0.3569 - val_accuracy: 0.8625\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2970 - accuracy: 0.8797 - val_loss: 0.3492 - val_accuracy: 0.8500\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2869 - accuracy: 0.8844 - val_loss: 0.3510 - val_accuracy: 0.8562\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2707 - accuracy: 0.8938 - val_loss: 0.3745 - val_accuracy: 0.8438\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2889 - accuracy: 0.8844 - val_loss: 0.3475 - val_accuracy: 0.8625\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3017 - accuracy: 0.8703 - val_loss: 0.3489 - val_accuracy: 0.8750\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3037 - accuracy: 0.8766 - val_loss: 0.3436 - val_accuracy: 0.8625\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2792 - accuracy: 0.8922 - val_loss: 0.3518 - val_accuracy: 0.8562\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2582 - accuracy: 0.8938 - val_loss: 0.3451 - val_accuracy: 0.8687\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2805 - accuracy: 0.8891 - val_loss: 0.3434 - val_accuracy: 0.8625\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2594 - accuracy: 0.8828 - val_loss: 0.3430 - val_accuracy: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2724 - accuracy: 0.8828 - val_loss: 0.3590 - val_accuracy: 0.8438\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2576 - accuracy: 0.8922 - val_loss: 0.3676 - val_accuracy: 0.8562\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2443 - accuracy: 0.9016 - val_loss: 0.3751 - val_accuracy: 0.8562\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2753 - accuracy: 0.8891 - val_loss: 0.3647 - val_accuracy: 0.8625\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2518 - accuracy: 0.8938 - val_loss: 0.3680 - val_accuracy: 0.8500\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2651 - accuracy: 0.8938 - val_loss: 0.3529 - val_accuracy: 0.8562\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2665 - accuracy: 0.8922 - val_loss: 0.3631 - val_accuracy: 0.8625\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2754 - accuracy: 0.8984 - val_loss: 0.3805 - val_accuracy: 0.8500\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2575 - accuracy: 0.8891 - val_loss: 0.3863 - val_accuracy: 0.8500\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2779 - accuracy: 0.8906 - val_loss: 0.3745 - val_accuracy: 0.8500\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2860 - accuracy: 0.8953 - val_loss: 0.3722 - val_accuracy: 0.8438\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2626 - accuracy: 0.8906 - val_loss: 0.3852 - val_accuracy: 0.8625\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2755 - accuracy: 0.8734 - val_loss: 0.3590 - val_accuracy: 0.8375\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2668 - accuracy: 0.8891 - val_loss: 0.3715 - val_accuracy: 0.8438\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2806 - accuracy: 0.8750 - val_loss: 0.3575 - val_accuracy: 0.8687\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2542 - accuracy: 0.8844 - val_loss: 0.3669 - val_accuracy: 0.8562\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2449 - accuracy: 0.8891 - val_loss: 0.3727 - val_accuracy: 0.8500\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2736 - accuracy: 0.8844 - val_loss: 0.3531 - val_accuracy: 0.8562\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2743 - accuracy: 0.8687 - val_loss: 0.3850 - val_accuracy: 0.8438\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2587 - accuracy: 0.8922 - val_loss: 0.3504 - val_accuracy: 0.8562\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2585 - accuracy: 0.8828 - val_loss: 0.3557 - val_accuracy: 0.8562\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2571 - accuracy: 0.8859 - val_loss: 0.3912 - val_accuracy: 0.8562\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2473 - accuracy: 0.8906 - val_loss: 0.4034 - val_accuracy: 0.8500\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2607 - accuracy: 0.8953 - val_loss: 0.3983 - val_accuracy: 0.8375\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2638 - accuracy: 0.8859 - val_loss: 0.3982 - val_accuracy: 0.8313\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2359 - accuracy: 0.8969 - val_loss: 0.3675 - val_accuracy: 0.8562\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2350 - accuracy: 0.8953 - val_loss: 0.3799 - val_accuracy: 0.8438\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2574 - accuracy: 0.8922 - val_loss: 0.3831 - val_accuracy: 0.8562\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2495 - accuracy: 0.8891 - val_loss: 0.3638 - val_accuracy: 0.8625\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2538 - accuracy: 0.8859 - val_loss: 0.3580 - val_accuracy: 0.8562\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2354 - accuracy: 0.8922 - val_loss: 0.3796 - val_accuracy: 0.8500\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2425 - accuracy: 0.8875 - val_loss: 0.3887 - val_accuracy: 0.8375\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2471 - accuracy: 0.8969 - val_loss: 0.4023 - val_accuracy: 0.8250\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2459 - accuracy: 0.8984 - val_loss: 0.3902 - val_accuracy: 0.8375\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2371 - accuracy: 0.8922 - val_loss: 0.3696 - val_accuracy: 0.8250\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2243 - accuracy: 0.9000 - val_loss: 0.3796 - val_accuracy: 0.8438\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2520 - accuracy: 0.8984 - val_loss: 0.3932 - val_accuracy: 0.8438\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2551 - accuracy: 0.8875 - val_loss: 0.3935 - val_accuracy: 0.8375\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2269 - accuracy: 0.8984 - val_loss: 0.4116 - val_accuracy: 0.8375\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2353 - accuracy: 0.8969 - val_loss: 0.3731 - val_accuracy: 0.8500\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2247 - accuracy: 0.9000 - val_loss: 0.4404 - val_accuracy: 0.8438\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2438 - accuracy: 0.8969 - val_loss: 0.3933 - val_accuracy: 0.8313\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4155 - accuracy: 0.8400\n",
      "Test Loss: 0.41547560691833496\n",
      "Test Accuracy: 83.99999737739563\n"
     ]
    }
   ],
   "source": [
    "# Create the hybrid model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Define the optimizer with adjusted learning rate\n",
    "optimizer = Adam(learning_rate=0.003)\n",
    "\n",
    "# Compile the model with the optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=26, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy*100)\n",
    "model.save('CNN-DNN.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3d46a0",
   "metadata": {},
   "source": [
    "Encoded values for attribute 'menopause':\n",
    "ge40: 0\n",
    "lt40: 1\n",
    "premeno: 2\n",
    "\n",
    "Encoded values for attribute 'node-caps':\n",
    "nan: 0\n",
    "no: 1\n",
    "yes: 2\n",
    "\n",
    "Encoded values for attribute 'breast':\n",
    "left: 0\n",
    "right: 1\n",
    "\n",
    "Encoded values for attribute 'breast-quad':\n",
    "central: 0\n",
    "left_low: 1\n",
    "left_up: 2\n",
    "nan: 3\n",
    "right_low: 4\n",
    "right_up: 5\n",
    "\n",
    "Encoded values for attribute 'irradiat':\n",
    "no: 0\n",
    "yes: 1\n",
    "\n",
    "Encoded values for attribute 'Class':\n",
    "no-recurrence-events: 0\n",
    "recurrence-events: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "a48fd347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=X_train[1]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "5155e4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "df711d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('CNN-DNN.h5')\n",
    "\n",
    "# Compile the model (if needed)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "c04f2407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "8a9741d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "print(model.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "989c7eb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Megha\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Megha\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Megha\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\Megha\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\Megha\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer 'conv1d_9' (type Conv1D).\n    \n    Negative dimension size caused by subtracting 3 from 1 for '{{node sequential_18/conv1d_9/Conv1D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](sequential_18/conv1d_9/Conv1D/ExpandDims, sequential_18/conv1d_9/Conv1D/ExpandDims_1)' with input shapes: [?,1,1,1], [1,3,1,32].\n    \n    Call arguments received by layer 'conv1d_9' (type Conv1D):\n      • inputs=tf.Tensor(shape=(None, 1, 1), dtype=float32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[295], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Convert predictions to labels\u001b[39;00m\n\u001b[0;32m      4\u001b[0m labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filemetnymvz.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Megha\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Megha\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Megha\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\Megha\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\Megha\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer 'conv1d_9' (type Conv1D).\n    \n    Negative dimension size caused by subtracting 3 from 1 for '{{node sequential_18/conv1d_9/Conv1D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](sequential_18/conv1d_9/Conv1D/ExpandDims, sequential_18/conv1d_9/Conv1D/ExpandDims_1)' with input shapes: [?,1,1,1], [1,3,1,32].\n    \n    Call arguments received by layer 'conv1d_9' (type Conv1D):\n      • inputs=tf.Tensor(shape=(None, 1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(data)\n",
    "\n",
    "# Convert predictions to labels\n",
    "labels = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e660f1e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642d7f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048627a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
